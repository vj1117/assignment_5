{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyxqZe9KjBMk"
      },
      "outputs": [],
      "source": [
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "Ys4wAHAYjDBR",
        "outputId": "8e27b0b6-723f-4b78-c7e9-b30efd611c0d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjohnced\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "0FLXVzDlujYb",
        "outputId": "c89ffdd5-907a-4816-868e-ff450065dc27"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "creating run (0.3s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250914_122515-xntprcd5</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/johnced/cnn_mnist/runs/xntprcd5' target=\"_blank\">desert-oath-4</a></strong> to <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/johnced/cnn_mnist/runs/xntprcd5' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist/runs/xntprcd5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a38237ac5b0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config = {\n",
        "    \"project\": \"cnn_mnist\",\n",
        "    \"entity\": None,            # set your wandb username/team if desired\n",
        "    \"epochs\": 15,\n",
        "    \"batch_size\": 64,\n",
        "    \"lr\": 0.001,\n",
        "    \"seed\": 42,\n",
        "    'use_augmentation': False,\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "}\n",
        "\n",
        "# You can call wandb.login() earlier if you haven't set env var.\n",
        "wandb.init(project=config[\"project\"], config=config)\n",
        "cfg = wandb.config\n",
        "\n",
        "# ------------------------------\n",
        "# Data loaders (MNIST)\n",
        "# ------------------------------\n",
        "torch.manual_seed(cfg.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q-mhL4Tj6lU"
      },
      "source": [
        "## Experiment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zviSlNDj997"
      },
      "source": [
        "1. Check current model size - given in original notebook\n",
        "2. Check image in paint and tentatively around 7 pixels can capture the edges. So, RF is 7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1) #input -? OUtput? RF\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv5 = nn.Conv2d(256, 512, 3)\n",
        "        self.conv6 = nn.Conv2d(512, 1024, 3)\n",
        "        self.conv7 = nn.Conv2d(1024, 10, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdydjYTZFyi3",
        "outputId": "789e641c-8fa5-452c-c339-8fc7e8d06a14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.12/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
            "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
            "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
            "            Conv2d-5          [-1, 256, 14, 14]         295,168\n",
            "         MaxPool2d-6            [-1, 256, 7, 7]               0\n",
            "            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n",
            "            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n",
            "            Conv2d-9             [-1, 10, 1, 1]          92,170\n",
            "================================================================\n",
            "Total params: 6,379,786\n",
            "Trainable params: 6,379,786\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.51\n",
            "Params size (MB): 24.34\n",
            "Estimated Total Size (MB): 25.85\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3267201574.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhSGHeRsm39C"
      },
      "outputs": [],
      "source": [
        "# Requires: torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from collections import OrderedDict\n",
        "\n",
        "def _to_2tuple(x):\n",
        "    if isinstance(x, tuple):\n",
        "        return x\n",
        "    return (x, x)\n",
        "\n",
        "def layer_info(layer):\n",
        "    \"\"\"Return (k, s, p, d, type) for conv/pool layers or None.\"\"\"\n",
        "    if isinstance(layer, nn.Conv2d):\n",
        "        k = _to_2tuple(layer.kernel_size)\n",
        "        s = _to_2tuple(layer.stride)\n",
        "        p = _to_2tuple(layer.padding)\n",
        "        d = _to_2tuple(layer.dilation)\n",
        "        return dict(type='conv', k=k, s=s, p=p, d=d, out_channels=layer.out_channels)\n",
        "    if isinstance(layer, nn.MaxPool2d) or isinstance(layer, nn.AvgPool2d):\n",
        "        k = _to_2tuple(layer.kernel_size)\n",
        "        s = _to_2tuple(layer.stride or layer.kernel_size)\n",
        "        p = _to_2tuple(layer.padding or 0)\n",
        "        d = (1,1)\n",
        "        return dict(type='pool', k=k, s=s, p=p, d=d)\n",
        "    return None\n",
        "\n",
        "def analyze_receptive_field(model, input_size=(1, 28, 28), batch_size=1):\n",
        "    \"\"\"\n",
        "    Prints receptive field analysis for model layers.\n",
        "    input_size: (C, H, W)\n",
        "    \"\"\"\n",
        "    C, H, W = input_size\n",
        "    # initial values\n",
        "    rf_h = 1\n",
        "    rf_w = 1\n",
        "    jump_h = 1\n",
        "    jump_w = 1\n",
        "    start_h = 0.5\n",
        "    start_w = 0.5\n",
        "\n",
        "    cur_h, cur_w = H, W\n",
        "\n",
        "    print(f\"{'layer':30} {'type':6} {'out_ch':6} {'k':9} {'s':9} {'p':9} {'out(HxW)':10} {'RF(HxW)':12} {'jump':8} {'start':12}\")\n",
        "    print(\"-\"*120)\n",
        "\n",
        "    # walk modules in order (skip top-level container)\n",
        "    idx = 0\n",
        "    for name, layer in model.named_modules():\n",
        "        # skip the top-level module itself\n",
        "        if name == \"\":\n",
        "            continue\n",
        "        info = layer_info(layer)\n",
        "        if info is None:\n",
        "            continue\n",
        "\n",
        "        idx += 1\n",
        "        typ = info['type']\n",
        "        k_h, k_w = info['k']\n",
        "        s_h, s_w = info['s']\n",
        "        p_h, p_w = info['p']\n",
        "        d_h, d_w = info['d']\n",
        "\n",
        "        # effective kernel size with dilation\n",
        "        eff_kh = d_h * (k_h - 1) + 1\n",
        "        eff_kw = d_w * (k_w - 1) + 1\n",
        "\n",
        "        # output spatial size formula: floor((in + 2p - dilation*(k-1)-1)/stride + 1)\n",
        "        out_h = math.floor( (cur_h + 2*p_h - d_h*(k_h-1) - 1) / s_h + 1 )\n",
        "        out_w = math.floor( (cur_w + 2*p_w - d_w*(k_w-1) - 1) / s_w + 1 )\n",
        "\n",
        "        # receptive field update\n",
        "        new_rf_h = rf_h + (eff_kh - 1) * jump_h\n",
        "        new_rf_w = rf_w + (eff_kw - 1) * jump_w\n",
        "\n",
        "        # jump update (how much a 1-px shift in input shifts output center)\n",
        "        new_jump_h = jump_h * s_h\n",
        "        new_jump_w = jump_w * s_w\n",
        "\n",
        "        # center (start) update -- position of the center of the top-left output unit\n",
        "        new_start_h = start_h + ((eff_kh - 1)/2 - p_h) * jump_h\n",
        "        new_start_w = start_w + ((eff_kw - 1)/2 - p_w) * jump_w\n",
        "\n",
        "        out_ch = info.get('out_channels', '-')\n",
        "        k_str = f\"{k_h}x{k_w}\"\n",
        "        s_str = f\"{s_h}x{s_w}\"\n",
        "        p_str = f\"{p_h}x{p_w}\"\n",
        "        rf_str = f\"{int(new_rf_h)}x{int(new_rf_w)}\"\n",
        "        jump_str = f\"{new_jump_h}x{new_jump_w}\"\n",
        "        start_str = f\"{new_start_h:.2f}x{new_start_w:.2f}\"\n",
        "\n",
        "        print(f\"{name:30} {typ:6} {str(out_ch):6} {k_str:9} {s_str:9} {p_str:9} {str(out_h)+'x'+str(out_w):10} {rf_str:12} {jump_str:8} {start_str:12}\")\n",
        "\n",
        "        # set for next iteration\n",
        "        rf_h, rf_w = new_rf_h, new_rf_w\n",
        "        jump_h, jump_w = new_jump_h, new_jump_w\n",
        "        start_h, start_w = new_start_h, new_start_w\n",
        "        cur_h, cur_w = out_h, out_w\n",
        "\n",
        "    print(\"-\"*120)\n",
        "    print(f\"Final output spatial size: {cur_h} x {cur_w}\")\n",
        "    print(f\"Final receptive field: {int(rf_h)} x {int(rf_w)}\")\n",
        "    print(f\"Final cumulative stride (jump): {jump_h} x {jump_w}\")\n",
        "    print(f\"Center of top-left output unit relative to input pixel (0-index approx): {start_h:.2f} , {start_w:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWgnX1blm_sg",
        "outputId": "d3c9add9-df03-4311-d170-8b4fa424029a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer                          type   out_ch k         s         p         out(HxW)   RF(HxW)      jump     start       \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "conv1                          conv   32     3x3       1x1       1x1       28x28      3x3          1x1      0.50x0.50   \n",
            "conv2                          conv   64     3x3       1x1       1x1       28x28      5x5          1x1      0.50x0.50   \n",
            "pool1                          pool   -      2x2       2x2       0x0       14x14      6x6          2x2      1.00x1.00   \n",
            "conv3                          conv   128    3x3       1x1       1x1       14x14      10x10        2x2      1.00x1.00   \n",
            "conv4                          conv   256    3x3       1x1       1x1       14x14      14x14        2x2      1.00x1.00   \n",
            "pool2                          pool   -      2x2       2x2       0x0       7x7        16x16        4x4      2.00x2.00   \n",
            "conv5                          conv   512    3x3       1x1       0x0       5x5        24x24        4x4      6.00x6.00   \n",
            "conv6                          conv   1024   3x3       1x1       0x0       3x3        32x32        4x4      10.00x10.00 \n",
            "conv7                          conv   10     3x3       1x1       0x0       1x1        40x40        4x4      14.00x14.00 \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Final output spatial size: 1 x 1\n",
            "Final receptive field: 40 x 40\n",
            "Final cumulative stride (jump): 4 x 4\n",
            "Center of top-left output unit relative to input pixel (0-index approx): 14.00 , 14.00\n"
          ]
        }
      ],
      "source": [
        "model = Net()\n",
        "analyze_receptive_field(model, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIizqiavvTuG"
      },
      "outputs": [],
      "source": [
        "wandb.watch(model, log=\"all\", log_freq=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnZY_AnAnhR7"
      },
      "source": [
        "1. Number of params is very large. Coming from the last few convolutional blocks\n",
        "2. Will start with #kernels as 8 instead of 32 and gradually increase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkRX3-j8pB38"
      },
      "outputs": [],
      "source": [
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQY3ljNdo8sS"
      },
      "outputs": [],
      "source": [
        "class ExperimentLogger:\n",
        "    \"\"\"Logger for tracking experiments and results\"\"\"\n",
        "\n",
        "    def __init__(self, experiment_name):\n",
        "        self.experiment_name = experiment_name\n",
        "        self.log_file = f\"experiment_log_{experiment_name}.csv\"\n",
        "        self.results = []\n",
        "        self.create_log_file()\n",
        "\n",
        "    def create_log_file(self):\n",
        "        \"\"\"Create CSV file with headers\"\"\"\n",
        "        headers = ['Experiment', 'Model', 'Total_Params', 'Train_Acc', 'Val_Acc',\n",
        "                  'Train_Loss', 'Val_Loss', 'Epochs', 'Best_Epoch', 'Has_BN',\n",
        "                  'Has_Dropout', 'Has_GAP', 'Has_FC', 'Learning_Rate', 'Scheduler',\n",
        "                  'Data_Augmentation', 'Comments']\n",
        "\n",
        "        with open(self.log_file, 'w', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(headers)\n",
        "\n",
        "    def log_experiment(self, exp_data):\n",
        "        \"\"\"Log experiment results\"\"\"\n",
        "        self.results.append(exp_data)\n",
        "        with open(self.log_file, 'a', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(exp_data.values())\n",
        "\n",
        "    def get_summary(self):\n",
        "        \"\"\"Get summary of all experiments\"\"\"\n",
        "        if not self.results:\n",
        "            return \"No experiments logged yet.\"\n",
        "\n",
        "        summary = f\"\\n=== EXPERIMENT SUMMARY ({self.experiment_name}) ===\\n\"\n",
        "        summary += f\"Total Experiments: {len(self.results)}\\n\\n\"\n",
        "\n",
        "        for i, result in enumerate(self.results, 1):\n",
        "            summary += f\"Experiment {i}:\\n\"\n",
        "            summary += f\"  Model: {result['Model']}\\n\"\n",
        "            summary += f\"  Parameters: {result['Total_Params']:,}\\n\"\n",
        "            summary += f\"  Best Val Accuracy: {result['Val_Acc']:.2f}%\\n\"\n",
        "            summary += f\"  Achieved Target (99.4%): {'✓' if result['Val_Acc'] >= 99.4 else '✗'}\\n\"\n",
        "            summary += f\"  Under 20k params: {'✓' if result['Total_Params'] < 20000 else '✗'}\\n\\n\"\n",
        "\n",
        "        return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rkwi5-a5oyOr"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    \"\"\"Count trainable parameters\"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtdUiDPWlPNJ"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, scheduler = None):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "        # Statistics\n",
        "        running_loss += loss.item()\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        total += target.size(0)\n",
        "\n",
        "        # Update progress bar\n",
        "        accuracy = 100. * correct / total\n",
        "        pbar.set_postfix({'Loss': f'{running_loss/(batch_idx+1):.4f}',\n",
        "                         'Acc': f'{accuracy:.2f}%'})\n",
        "        wandb.log({\"train/epoch_loss\": running_loss/(batch_idx+1), \"train/epoch_acc\": accuracy, \"epoch\": epoch})\n",
        "\n",
        "    return running_loss / len(train_loader), accuracy\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    wandb.log({\"test_loss\": test_loss, \"test/epoch_acc\": accuracy})\n",
        "\n",
        "    return test_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSjz7X-03Rt0"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, device, train_loader, optimizer, scheduler=None):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc='Training')\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Statistics\n",
        "        running_loss += loss.item()\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        total += target.size(0)\n",
        "\n",
        "        # Update progress bar\n",
        "        accuracy = 100. * correct / total\n",
        "        pbar.set_postfix({'Loss': f'{running_loss/(batch_idx+1):.4f}',\n",
        "                         'Acc': f'{accuracy:.2f}%'})\n",
        "\n",
        "    wandb.log({\"train/epoch_loss\": running_loss / len(train_loader), \"train/epoch_acc\": accuracy})\n",
        "\n",
        "    return running_loss / len(train_loader), accuracy\n",
        "\n",
        "def test_epoch(model, device, test_loader):\n",
        "    \"\"\"Test for one epoch\"\"\"\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    wandb.log({\"test_loss\": test_loss, \"test_acc\": accuracy})\n",
        "\n",
        "    return test_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxCi-ya8owr0"
      },
      "outputs": [],
      "source": [
        "def check_model_requirements(model):\n",
        "    \"\"\"Check if model meets requirements\"\"\"\n",
        "    total_params = count_parameters(model)\n",
        "\n",
        "    # Check for Batch Normalization\n",
        "    has_bn = any(isinstance(m, nn.BatchNorm2d) for m in model.modules())\n",
        "\n",
        "    # Check for Dropout\n",
        "    has_dropout = any(isinstance(m, (nn.Dropout, nn.Dropout2d)) for m in model.modules())\n",
        "\n",
        "    # Check for Global Average Pooling\n",
        "    has_gap = any(isinstance(m, (nn.AdaptiveAvgPool2d, nn.AvgPool2d)) for m in model.modules())\n",
        "\n",
        "    # Check for Fully Connected layers\n",
        "    has_fc = any(isinstance(m, nn.Linear) for m in model.modules())\n",
        "\n",
        "    return {\n",
        "        'total_params': total_params,\n",
        "        'under_20k': total_params < 20000,\n",
        "        'has_bn': has_bn,\n",
        "        'has_dropout': has_dropout,\n",
        "        'has_gap': has_gap,\n",
        "        'has_fc': has_fc\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCCdtKqBnRbp"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import OneCycleLR, StepLR\n",
        "\n",
        "def run_experiment(model_class, model_name, experiment_name, epochs=15, learning_rate=0.01,\n",
        "                  scheduler_type='onecycle', use_augmentation=False, dropout_rate=0.1):\n",
        "    \"\"\"Run a complete experiment\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Running Experiment: {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Setup device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Initialize model\n",
        "    model = model_class(dropout_rate=dropout_rate).to(device)\n",
        "    requirements = check_model_requirements(model)\n",
        "\n",
        "    print(f\"\\nModel Requirements Check:\")\n",
        "    print(f\"  Total Parameters: {requirements['total_params']:,}\")\n",
        "    print(f\"  Under 20k params: {'✓' if requirements['under_20k'] else '✗'}\")\n",
        "    print(f\"  Has Batch Normalization: {'✓' if requirements['has_bn'] else '✗'}\")\n",
        "    print(f\"  Has Dropout: {'✓' if requirements['has_dropout'] else '✗'}\")\n",
        "    print(f\"  Has Global Average Pooling: {'✓' if requirements['has_gap'] else '✗'}\")\n",
        "    print(f\"  Has Fully Connected Layer: {'✓' if requirements['has_fc'] else '✗'}\")\n",
        "\n",
        "    # Get data loaders\n",
        "    train_loader, test_loader = get_data_loaders(use_augmentation=use_augmentation)\n",
        "\n",
        "    # Setup optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "\n",
        "    # Setup scheduler\n",
        "    if scheduler_type == 'onecycle':\n",
        "        scheduler = OneCycleLR(optimizer, max_lr=learning_rate*10,\n",
        "                             epochs=epochs, steps_per_epoch=len(train_loader))\n",
        "    elif scheduler_type == 'step':\n",
        "        scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "    else:\n",
        "        scheduler = None\n",
        "\n",
        "    # Training loop\n",
        "    best_val_acc = 0\n",
        "    best_epoch = 0\n",
        "    train_losses, train_accs = [], []\n",
        "    val_losses, val_accs = [], []\n",
        "\n",
        "    print(f\"\\nStarting Training for {epochs} epochs...\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
        "\n",
        "        # Train\n",
        "        #train_loss, train_acc = train(model, device, train_loader, optimizer,\n",
        "        #                                  scheduler if scheduler_type == 'onecycle' else None)\n",
        "\n",
        "        # Test\n",
        "        #val_loss, val_acc = test(model, device, test_loader)\n",
        "\n",
        "        train_loss, train_acc = train_epoch(model, device, train_loader, optimizer,\n",
        "                                          scheduler if scheduler_type == 'onecycle' else None)\n",
        "\n",
        "        # Test\n",
        "        val_loss, val_acc = test_epoch(model, device, test_loader)\n",
        "\n",
        "        # Update scheduler (for step scheduler)\n",
        "        if scheduler_type == 'step' and scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Track best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_epoch = epoch\n",
        "            # Save best model\n",
        "            torch.save(model.state_dict(), f'best_{model_name.lower()}.pth')\n",
        "\n",
        "        # Store metrics\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "        print(f\"Best Val Acc: {best_val_acc:.2f}% (Epoch {best_epoch})\")\n",
        "\n",
        "    # Final results\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"EXPERIMENT COMPLETED: {model_name}\")\n",
        "    print(f\"{'='*40}\")\n",
        "    print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "    print(f\"Target Achievement (99.4%): {'✓' if best_val_acc >= 99.4 else '✗'}\")\n",
        "    print(f\"Parameter Efficiency (<20k): {'✓' if requirements['under_20k'] else '✗'}\")\n",
        "\n",
        "    # Log experiment\n",
        "    logger = ExperimentLogger(experiment_name)\n",
        "    exp_data = {\n",
        "        'Experiment': len(logger.results) + 1,\n",
        "        'Model': model_name,\n",
        "        'Total_Params': requirements['total_params'],\n",
        "        'Train_Acc': train_accs[-1],\n",
        "        'Val_Acc': best_val_acc,\n",
        "        'Train_Loss': train_losses[-1],\n",
        "        'Val_Loss': val_losses[val_accs.index(max(val_accs))],\n",
        "        'Epochs': epochs,\n",
        "        'Best_Epoch': best_epoch,\n",
        "        'Has_BN': requirements['has_bn'],\n",
        "        'Has_Dropout': requirements['has_dropout'],\n",
        "        'Has_GAP': requirements['has_gap'],\n",
        "        'Has_FC': requirements['has_fc'],\n",
        "        'Learning_Rate': learning_rate,\n",
        "        'Scheduler': scheduler_type,\n",
        "        'Data_Augmentation': use_augmentation,\n",
        "        'Comments': f\"Dropout: {dropout_rate}\"\n",
        "    }\n",
        "    logger.log_experiment(exp_data)\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'best_val_acc': best_val_acc,\n",
        "        'requirements': requirements,\n",
        "        'train_history': (train_losses, train_accs, val_losses, val_accs)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "outputs": [],
      "source": [
        "def get_data_loaders(batch_size=64, use_augmentation=False):\n",
        "  \"\"\"Get data loaders\"\"\"\n",
        "\n",
        "  torch.manual_seed(1)\n",
        "\n",
        "  kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "  return train_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmegWzWS_IV3"
      },
      "outputs": [],
      "source": [
        "class Small_MNIST1(nn.Module):\n",
        "    \"\"\"\n",
        "    Small CNN Architecture v1\n",
        "    - Basic efficient design with BN and Dropout\n",
        "    - Uses Global Average Pooling\n",
        "    - Target: <20k parameters, >99.4% accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dropout_rate=0.1):\n",
        "        super(Small_MNIST1, self).__init__()\n",
        "\n",
        "        # Feature extraction layers\n",
        "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
        "\n",
        "        # Pooling and regularization\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(16, 16, 3, padding=1)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "\n",
        "        # Final classification layer\n",
        "        self.conv6 = nn.Conv2d(32, 10, 3)  # No BN after final conv\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # Block 3 & Classification\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = F.relu(self.conv6(x))  # 7x7 -> 5x5\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7twBCJR8_7Lx",
        "outputId": "5ff26d67-1392-4b79-8379-1d3a85aebe5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.12/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              80\n",
            "            Conv2d-2           [-1, 16, 28, 28]           1,168\n",
            "         MaxPool2d-3           [-1, 16, 14, 14]               0\n",
            "            Conv2d-4           [-1, 16, 14, 14]           2,320\n",
            "            Conv2d-5           [-1, 32, 14, 14]           4,640\n",
            "         MaxPool2d-6             [-1, 32, 7, 7]               0\n",
            "            Conv2d-7             [-1, 32, 7, 7]           9,248\n",
            "            Conv2d-8             [-1, 10, 5, 5]           2,890\n",
            "================================================================\n",
            "Total params: 20,346\n",
            "Trainable params: 20,346\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.27\n",
            "Params size (MB): 0.08\n",
            "Estimated Total Size (MB): 0.35\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Small_MNIST1().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFpbqh6eBCiZ",
        "outputId": "ebcd4b6b-98e9-454c-d6ce-3d7a7322f257"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer                          type   out_ch k         s         p         out(HxW)   RF(HxW)      jump     start       \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "conv1                          conv   8      3x3       1x1       1x1       28x28      3x3          1x1      0.50x0.50   \n",
            "conv2                          conv   16     3x3       1x1       1x1       28x28      5x5          1x1      0.50x0.50   \n",
            "pool1                          pool   -      2x2       2x2       0x0       14x14      6x6          2x2      1.00x1.00   \n",
            "conv3                          conv   16     3x3       1x1       1x1       14x14      10x10        2x2      1.00x1.00   \n",
            "conv4                          conv   32     3x3       1x1       1x1       14x14      14x14        2x2      1.00x1.00   \n",
            "pool2                          pool   -      2x2       2x2       0x0       7x7        16x16        4x4      2.00x2.00   \n",
            "conv5                          conv   32     3x3       1x1       1x1       7x7        24x24        4x4      2.00x2.00   \n",
            "conv6                          conv   10     3x3       1x1       0x0       5x5        32x32        4x4      6.00x6.00   \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Final output spatial size: 5 x 5\n",
            "Final receptive field: 32 x 32\n",
            "Final cumulative stride (jump): 4 x 4\n",
            "Center of top-left output unit relative to input pixel (0-index approx): 6.00 , 6.00\n"
          ]
        }
      ],
      "source": [
        "model = Small_MNIST1(dropout_rate=0.1)\n",
        "analyze_receptive_field(model, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6RaU-VtBPob",
        "outputId": "510d620c-1b5f-41ff-bd41-b4c1de471319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Experimental Suite: MNIST_CNN_20250914_191005\n",
            "Target: 99.4% accuracy with <20k parameters in <20 epochs\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "results = []\n",
        "\n",
        "experiment_name = f\"MNIST_CNN_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "print(f\"Starting Experimental Suite: {experiment_name}\")\n",
        "print(f\"Target: 99.4% accuracy with <20k parameters in <20 epochs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMkZhUTBBPob"
      },
      "outputs": [],
      "source": [
        "exp_config = {\n",
        "        'model_class': Small_MNIST1,\n",
        "        'model_name': 'Small_MNIST1',\n",
        "        'epochs': 15,\n",
        "        'learning_rate': 0.001,\n",
        "        'use_augmentation': False\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIjl0CghBPob",
        "outputId": "2ff1787b-61a3-41f4-ea48-5ef09d155578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Running Experiment: Small_MNIST1\n",
            "============================================================\n",
            "Using device: cuda\n",
            "\n",
            "Model Requirements Check:\n",
            "  Total Parameters: 20,346\n",
            "  Under 20k params: ✗\n",
            "  Has Batch Normalization: ✗\n",
            "  Has Dropout: ✗\n",
            "  Has Global Average Pooling: ✗\n",
            "  Has Fully Connected Layer: ✗\n",
            "\n",
            "Starting Training for 15 epochs...\n",
            "\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:24<00:00, 38.70it/s, Loss=1.4144, Acc=56.41%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.4144, Train Acc: 56.41%\n",
            "Val Loss: 0.4356, Val Acc: 86.97%\n",
            "Best Val Acc: 86.97% (Epoch 1)\n",
            "\n",
            "Epoch 2/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.06it/s, Loss=0.2678, Acc=91.96%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2678, Train Acc: 91.96%\n",
            "Val Loss: 0.1797, Val Acc: 94.40%\n",
            "Best Val Acc: 94.40% (Epoch 2)\n",
            "\n",
            "Epoch 3/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.83it/s, Loss=0.1609, Acc=95.16%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1609, Train Acc: 95.16%\n",
            "Val Loss: 0.1500, Val Acc: 95.83%\n",
            "Best Val Acc: 95.83% (Epoch 3)\n",
            "\n",
            "Epoch 4/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.67it/s, Loss=0.1288, Acc=96.25%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1288, Train Acc: 96.25%\n",
            "Val Loss: 0.1380, Val Acc: 95.95%\n",
            "Best Val Acc: 95.95% (Epoch 4)\n",
            "\n",
            "Epoch 5/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.38it/s, Loss=0.1145, Acc=96.59%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1145, Train Acc: 96.59%\n",
            "Val Loss: 0.1663, Val Acc: 95.50%\n",
            "Best Val Acc: 95.95% (Epoch 4)\n",
            "\n",
            "Epoch 6/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.28it/s, Loss=0.1012, Acc=97.06%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1012, Train Acc: 97.06%\n",
            "Val Loss: 0.1281, Val Acc: 96.05%\n",
            "Best Val Acc: 96.05% (Epoch 6)\n",
            "\n",
            "Epoch 7/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.20it/s, Loss=0.0915, Acc=97.38%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0915, Train Acc: 97.38%\n",
            "Val Loss: 0.0845, Val Acc: 97.61%\n",
            "Best Val Acc: 97.61% (Epoch 7)\n",
            "\n",
            "Epoch 8/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.60it/s, Loss=0.0768, Acc=97.79%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0768, Train Acc: 97.79%\n",
            "Val Loss: 0.0727, Val Acc: 97.95%\n",
            "Best Val Acc: 97.95% (Epoch 8)\n",
            "\n",
            "Epoch 9/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.71it/s, Loss=0.0662, Acc=98.06%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0662, Train Acc: 98.06%\n",
            "Val Loss: 0.0796, Val Acc: 97.71%\n",
            "Best Val Acc: 97.95% (Epoch 8)\n",
            "\n",
            "Epoch 10/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.99it/s, Loss=0.0529, Acc=98.35%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0529, Train Acc: 98.35%\n",
            "Val Loss: 0.0691, Val Acc: 97.90%\n",
            "Best Val Acc: 97.95% (Epoch 8)\n",
            "\n",
            "Epoch 11/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.10it/s, Loss=0.0362, Acc=98.91%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0362, Train Acc: 98.91%\n",
            "Val Loss: 0.0480, Val Acc: 98.60%\n",
            "Best Val Acc: 98.60% (Epoch 11)\n",
            "\n",
            "Epoch 12/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.88it/s, Loss=0.0237, Acc=99.27%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0237, Train Acc: 99.27%\n",
            "Val Loss: 0.0421, Val Acc: 98.75%\n",
            "Best Val Acc: 98.75% (Epoch 12)\n",
            "\n",
            "Epoch 13/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.86it/s, Loss=0.0126, Acc=99.65%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0126, Train Acc: 99.65%\n",
            "Val Loss: 0.0373, Val Acc: 98.94%\n",
            "Best Val Acc: 98.94% (Epoch 13)\n",
            "\n",
            "Epoch 14/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.21it/s, Loss=0.0059, Acc=99.87%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0059, Train Acc: 99.87%\n",
            "Val Loss: 0.0362, Val Acc: 98.89%\n",
            "Best Val Acc: 98.94% (Epoch 13)\n",
            "\n",
            "Epoch 15/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.41it/s, Loss=0.0036, Acc=99.95%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0036, Train Acc: 99.95%\n",
            "Val Loss: 0.0353, Val Acc: 98.98%\n",
            "Best Val Acc: 98.98% (Epoch 15)\n",
            "\n",
            "========================================\n",
            "EXPERIMENT COMPLETED: Small_MNIST1\n",
            "========================================\n",
            "Best Validation Accuracy: 98.98%\n",
            "Target Achievement (99.4%): ✗\n",
            "Parameter Efficiency (<20k): ✗\n"
          ]
        }
      ],
      "source": [
        "result = run_experiment(experiment_name=experiment_name, **exp_config)\n",
        "results.append(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpxHFqMITq-E"
      },
      "source": [
        "Observations:\n",
        "1. Train Accuracy - 99.95%\n",
        "Test Accuracy - 98.98%\n",
        "2. First target is to further reduce the number of parameters.\n",
        "3. Let us make use of 1x1 point wise convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9YhzSJ5RX1R"
      },
      "outputs": [],
      "source": [
        "class Small_MNIST2(nn.Module):\n",
        "    \"\"\"\n",
        "    Small CNN Architecture v1\n",
        "    - Basic efficient design with BN and Dropout\n",
        "    - Uses Global Average Pooling\n",
        "    - Target: <20k parameters, >99.4% accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dropout_rate=0.1):\n",
        "        super(Small_MNIST2, self).__init__()\n",
        "\n",
        "        # Feature extraction layers\n",
        "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(8, 16, 1, padding=1)\n",
        "\n",
        "        # Pooling and regularization\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(16, 16, 3, padding=1)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(16, 32, 1, padding=1)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "\n",
        "        # Final classification layer\n",
        "        self.conv6 = nn.Conv2d(32, 10, 3)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # Block 3 & Classification\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = F.relu(self.conv6(x))  # 7x7 -> 5x5\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SquGYZupWZ_H",
        "outputId": "854bc0af-7624-4906-c839-8b95607e7c83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.12/dist-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "\n",
        "def model_summary_and_rf(model):\n",
        "  use_cuda = torch.cuda.is_available()\n",
        "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "  model = model.to(device)\n",
        "  summary(model, input_size=(1, 28, 28))\n",
        "\n",
        "  analyze_receptive_field(model, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLbOp2eDWvjq",
        "outputId": "8d5597ed-2e95-4883-f082-0ccf532596c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              80\n",
            "            Conv2d-2           [-1, 16, 30, 30]             144\n",
            "         MaxPool2d-3           [-1, 16, 15, 15]               0\n",
            "            Conv2d-4           [-1, 16, 15, 15]           2,320\n",
            "            Conv2d-5           [-1, 32, 17, 17]             544\n",
            "         MaxPool2d-6             [-1, 32, 8, 8]               0\n",
            "            Conv2d-7             [-1, 32, 8, 8]           9,248\n",
            "            Conv2d-8             [-1, 10, 6, 6]           2,890\n",
            "================================================================\n",
            "Total params: 15,226\n",
            "Trainable params: 15,226\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.32\n",
            "Params size (MB): 0.06\n",
            "Estimated Total Size (MB): 0.38\n",
            "----------------------------------------------------------------\n",
            "layer                          type   out_ch k         s         p         out(HxW)   RF(HxW)      jump     start       \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "conv1                          conv   8      3x3       1x1       1x1       28x28      3x3          1x1      0.50x0.50   \n",
            "conv2                          conv   16     1x1       1x1       1x1       30x30      3x3          1x1      -0.50x-0.50 \n",
            "pool1                          pool   -      2x2       2x2       0x0       15x15      4x4          2x2      0.00x0.00   \n",
            "conv3                          conv   16     3x3       1x1       1x1       15x15      8x8          2x2      0.00x0.00   \n",
            "conv4                          conv   32     1x1       1x1       1x1       17x17      8x8          2x2      -2.00x-2.00 \n",
            "pool2                          pool   -      2x2       2x2       0x0       8x8        10x10        4x4      -1.00x-1.00 \n",
            "conv5                          conv   32     3x3       1x1       1x1       8x8        18x18        4x4      -1.00x-1.00 \n",
            "conv6                          conv   10     3x3       1x1       0x0       6x6        26x26        4x4      3.00x3.00   \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Final output spatial size: 6 x 6\n",
            "Final receptive field: 26 x 26\n",
            "Final cumulative stride (jump): 4 x 4\n",
            "Center of top-left output unit relative to input pixel (0-index approx): 3.00 , 3.00\n"
          ]
        }
      ],
      "source": [
        "model_summary_and_rf(Small_MNIST2())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeG7GE8IX18y"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def create_and_run():\n",
        "\n",
        "  experiment_name = f\"MNIST_CNN_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "  print(f\"Starting Experimental Suite: {experiment_name}\")\n",
        "  print(f\"Target: 99.4% accuracy with <20k parameters in <20 epochs\")\n",
        "\n",
        "  exp_config = {\n",
        "        'model_class': Small_MNIST2,\n",
        "        'model_name': 'Small_MNIST2',\n",
        "        'epochs': 15,\n",
        "        'learning_rate': 0.001,\n",
        "        'use_augmentation': False\n",
        "    }\n",
        "\n",
        "  result = run_experiment(experiment_name=experiment_name, **exp_config)\n",
        "  results.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr7DLXEjYUJK",
        "outputId": "1a7733aa-4308-4a82-956a-c4c228d00dff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Experimental Suite: MNIST_CNN_20250914_131927\n",
            "Target: 99.4% accuracy with <20k parameters in <20 epochs\n",
            "\n",
            "============================================================\n",
            "Running Experiment: Small_MNIST2\n",
            "============================================================\n",
            "Using device: cuda\n",
            "\n",
            "Model Requirements Check:\n",
            "  Total Parameters: 15,226\n",
            "  Under 20k params: ✓\n",
            "  Has Batch Normalization: ✗\n",
            "  Has Dropout: ✗\n",
            "  Has Global Average Pooling: ✗\n",
            "  Has Fully Connected Layer: ✗\n",
            "\n",
            "Starting Training for 15 epochs...\n",
            "\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.20it/s, Loss=1.8465, Acc=42.36%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.8465, Train Acc: 42.36%\n",
            "Val Loss: 0.7840, Val Acc: 75.26%\n",
            "Best Val Acc: 75.26% (Epoch 1)\n",
            "\n",
            "Epoch 2/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.06it/s, Loss=0.6311, Acc=80.31%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6311, Train Acc: 80.31%\n",
            "Val Loss: 0.4586, Val Acc: 85.85%\n",
            "Best Val Acc: 85.85% (Epoch 2)\n",
            "\n",
            "Epoch 3/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.76it/s, Loss=0.3992, Acc=87.54%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3992, Train Acc: 87.54%\n",
            "Val Loss: 0.3531, Val Acc: 88.65%\n",
            "Best Val Acc: 88.65% (Epoch 3)\n",
            "\n",
            "Epoch 4/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.00it/s, Loss=0.3080, Acc=90.53%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3080, Train Acc: 90.53%\n",
            "Val Loss: 0.2575, Val Acc: 91.68%\n",
            "Best Val Acc: 91.68% (Epoch 4)\n",
            "\n",
            "Epoch 5/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.82it/s, Loss=0.2541, Acc=92.28%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2541, Train Acc: 92.28%\n",
            "Val Loss: 0.2337, Val Acc: 93.05%\n",
            "Best Val Acc: 93.05% (Epoch 5)\n",
            "\n",
            "Epoch 6/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:18<00:00, 49.73it/s, Loss=0.2219, Acc=93.20%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2219, Train Acc: 93.20%\n",
            "Val Loss: 0.1800, Val Acc: 94.50%\n",
            "Best Val Acc: 94.50% (Epoch 6)\n",
            "\n",
            "Epoch 7/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.39it/s, Loss=0.1969, Acc=93.89%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1969, Train Acc: 93.89%\n",
            "Val Loss: 0.1795, Val Acc: 94.82%\n",
            "Best Val Acc: 94.82% (Epoch 7)\n",
            "\n",
            "Epoch 8/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.22it/s, Loss=0.1757, Acc=94.53%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1757, Train Acc: 94.53%\n",
            "Val Loss: 0.1522, Val Acc: 95.11%\n",
            "Best Val Acc: 95.11% (Epoch 8)\n",
            "\n",
            "Epoch 9/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:18<00:00, 49.52it/s, Loss=0.1540, Acc=95.22%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1540, Train Acc: 95.22%\n",
            "Val Loss: 0.1480, Val Acc: 95.27%\n",
            "Best Val Acc: 95.27% (Epoch 9)\n",
            "\n",
            "Epoch 10/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.46it/s, Loss=0.1347, Acc=95.67%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1347, Train Acc: 95.67%\n",
            "Val Loss: 0.1394, Val Acc: 95.68%\n",
            "Best Val Acc: 95.68% (Epoch 10)\n",
            "\n",
            "Epoch 11/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 44.83it/s, Loss=0.1121, Acc=96.38%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1121, Train Acc: 96.38%\n",
            "Val Loss: 0.1274, Val Acc: 96.04%\n",
            "Best Val Acc: 96.04% (Epoch 11)\n",
            "\n",
            "Epoch 12/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.44it/s, Loss=0.0928, Acc=97.01%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0928, Train Acc: 97.01%\n",
            "Val Loss: 0.1055, Val Acc: 96.89%\n",
            "Best Val Acc: 96.89% (Epoch 12)\n",
            "\n",
            "Epoch 13/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 49.12it/s, Loss=0.0721, Acc=97.68%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0721, Train Acc: 97.68%\n",
            "Val Loss: 0.1005, Val Acc: 97.07%\n",
            "Best Val Acc: 97.07% (Epoch 13)\n",
            "\n",
            "Epoch 14/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.72it/s, Loss=0.0579, Acc=98.20%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0579, Train Acc: 98.20%\n",
            "Val Loss: 0.0961, Val Acc: 97.29%\n",
            "Best Val Acc: 97.29% (Epoch 14)\n",
            "\n",
            "Epoch 15/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.38it/s, Loss=0.0501, Acc=98.47%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0501, Train Acc: 98.47%\n",
            "Val Loss: 0.0974, Val Acc: 97.27%\n",
            "Best Val Acc: 97.29% (Epoch 14)\n",
            "\n",
            "========================================\n",
            "EXPERIMENT COMPLETED: Small_MNIST2\n",
            "========================================\n",
            "Best Validation Accuracy: 97.29%\n",
            "Target Achievement (99.4%): ✗\n",
            "Parameter Efficiency (<20k): ✓\n"
          ]
        }
      ],
      "source": [
        "create_and_run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnziYPIzZvrt"
      },
      "source": [
        "Train Accuracy - 98.47%\n",
        "Test Accuracy - 97.29%\n",
        "\n",
        "Next run, let us add some batch normalization for better training and check the impact on validation accuracy\n",
        "\n",
        "We will increase the number of epochs to 18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1mnhy4Laov2"
      },
      "outputs": [],
      "source": [
        "class Small_MNIST3(nn.Module):\n",
        "    \"\"\"\n",
        "    Small CNN Architecture v1\n",
        "    - Basic efficient design with BN and Dropout\n",
        "    - Uses Global Average Pooling\n",
        "    - Target: <20k parameters, >99.4% accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dropout_rate=0.1):\n",
        "        super(Small_MNIST3, self).__init__()\n",
        "\n",
        "        # Feature extraction layers\n",
        "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(8, 16, 1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "\n",
        "        # Pooling and regularization\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(16, 16, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(16, 32, 1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "\n",
        "        # Final classification layer\n",
        "        self.conv6 = nn.Conv2d(32, 10, 3)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # Block 3 & Classification\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = F.relu(self.conv6(x))  # 7x7 -> 5x5\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc3p0Ze7ao4s",
        "outputId": "cc607b9c-f5e8-4f62-d2f4-3e7e356977f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              80\n",
            "       BatchNorm2d-2            [-1, 8, 28, 28]              16\n",
            "            Conv2d-3           [-1, 16, 30, 30]             144\n",
            "       BatchNorm2d-4           [-1, 16, 30, 30]              32\n",
            "         MaxPool2d-5           [-1, 16, 15, 15]               0\n",
            "            Conv2d-6           [-1, 16, 15, 15]           2,320\n",
            "       BatchNorm2d-7           [-1, 16, 15, 15]              32\n",
            "            Conv2d-8           [-1, 32, 17, 17]             544\n",
            "       BatchNorm2d-9           [-1, 32, 17, 17]              64\n",
            "        MaxPool2d-10             [-1, 32, 8, 8]               0\n",
            "           Conv2d-11             [-1, 32, 8, 8]           9,248\n",
            "           Conv2d-12             [-1, 10, 6, 6]           2,890\n",
            "================================================================\n",
            "Total params: 15,370\n",
            "Trainable params: 15,370\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.57\n",
            "Params size (MB): 0.06\n",
            "Estimated Total Size (MB): 0.63\n",
            "----------------------------------------------------------------\n",
            "layer                          type   out_ch k         s         p         out(HxW)   RF(HxW)      jump     start       \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "conv1                          conv   8      3x3       1x1       1x1       28x28      3x3          1x1      0.50x0.50   \n",
            "conv2                          conv   16     1x1       1x1       1x1       30x30      3x3          1x1      -0.50x-0.50 \n",
            "pool1                          pool   -      2x2       2x2       0x0       15x15      4x4          2x2      0.00x0.00   \n",
            "conv3                          conv   16     3x3       1x1       1x1       15x15      8x8          2x2      0.00x0.00   \n",
            "conv4                          conv   32     1x1       1x1       1x1       17x17      8x8          2x2      -2.00x-2.00 \n",
            "pool2                          pool   -      2x2       2x2       0x0       8x8        10x10        4x4      -1.00x-1.00 \n",
            "conv5                          conv   32     3x3       1x1       1x1       8x8        18x18        4x4      -1.00x-1.00 \n",
            "conv6                          conv   10     3x3       1x1       0x0       6x6        26x26        4x4      3.00x3.00   \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Final output spatial size: 6 x 6\n",
            "Final receptive field: 26 x 26\n",
            "Final cumulative stride (jump): 4 x 4\n",
            "Center of top-left output unit relative to input pixel (0-index approx): 3.00 , 3.00\n"
          ]
        }
      ],
      "source": [
        "model_summary_and_rf(Small_MNIST3())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOVmJAyza8lw"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def create_and_run(exp_config):\n",
        "\n",
        "  experiment_name = f\"MNIST_CNN_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "  print(f\"Starting Experimental Suite: {experiment_name}\")\n",
        "  print(f\"Target: 99.4% accuracy with <20k parameters in <20 epochs\")\n",
        "\n",
        "  result = run_experiment(experiment_name=experiment_name, **exp_config)\n",
        "  results.append(result)\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEPki6hfapAN",
        "outputId": "99bb5eee-89dc-457e-88be-85456db46e50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Experimental Suite: MNIST_CNN_20250914_134339\n",
            "Target: 99.4% accuracy with <20k parameters in <20 epochs\n",
            "\n",
            "============================================================\n",
            "Running Experiment: Small_MNIST2\n",
            "============================================================\n",
            "Using device: cuda\n",
            "\n",
            "Model Requirements Check:\n",
            "  Total Parameters: 15,370\n",
            "  Under 20k params: ✓\n",
            "  Has Batch Normalization: ✓\n",
            "  Has Dropout: ✗\n",
            "  Has Global Average Pooling: ✗\n",
            "  Has Fully Connected Layer: ✗\n",
            "\n",
            "Starting Training for 18 epochs...\n",
            "\n",
            "Epoch 1/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 46.98it/s, Loss=1.0550, Acc=66.10%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.0550, Train Acc: 66.10%\n",
            "Val Loss: 0.3617, Val Acc: 89.15%\n",
            "Best Val Acc: 89.15% (Epoch 1)\n",
            "\n",
            "Epoch 2/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.19it/s, Loss=0.3134, Acc=90.12%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3134, Train Acc: 90.12%\n",
            "Val Loss: 0.2538, Val Acc: 92.19%\n",
            "Best Val Acc: 92.19% (Epoch 2)\n",
            "\n",
            "Epoch 3/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 49.33it/s, Loss=0.2400, Acc=92.49%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2400, Train Acc: 92.49%\n",
            "Val Loss: 0.2205, Val Acc: 93.13%\n",
            "Best Val Acc: 93.13% (Epoch 3)\n",
            "\n",
            "Epoch 4/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.68it/s, Loss=0.2052, Acc=93.66%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2052, Train Acc: 93.66%\n",
            "Val Loss: 0.2001, Val Acc: 93.90%\n",
            "Best Val Acc: 93.90% (Epoch 4)\n",
            "\n",
            "Epoch 5/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.24it/s, Loss=0.1834, Acc=94.33%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1834, Train Acc: 94.33%\n",
            "Val Loss: 0.1715, Val Acc: 94.60%\n",
            "Best Val Acc: 94.60% (Epoch 5)\n",
            "\n",
            "Epoch 6/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.22it/s, Loss=0.1705, Acc=94.69%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1705, Train Acc: 94.69%\n",
            "Val Loss: 0.1366, Val Acc: 95.74%\n",
            "Best Val Acc: 95.74% (Epoch 6)\n",
            "\n",
            "Epoch 7/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.60it/s, Loss=0.1519, Acc=95.20%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1519, Train Acc: 95.20%\n",
            "Val Loss: 0.1672, Val Acc: 94.99%\n",
            "Best Val Acc: 95.74% (Epoch 6)\n",
            "\n",
            "Epoch 8/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.77it/s, Loss=0.1442, Acc=95.50%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1442, Train Acc: 95.50%\n",
            "Val Loss: 0.1453, Val Acc: 95.39%\n",
            "Best Val Acc: 95.74% (Epoch 6)\n",
            "\n",
            "Epoch 9/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.99it/s, Loss=0.1354, Acc=95.72%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1354, Train Acc: 95.72%\n",
            "Val Loss: 0.1272, Val Acc: 96.30%\n",
            "Best Val Acc: 96.30% (Epoch 9)\n",
            "\n",
            "Epoch 10/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.77it/s, Loss=0.1238, Acc=96.11%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1238, Train Acc: 96.11%\n",
            "Val Loss: 0.1340, Val Acc: 95.62%\n",
            "Best Val Acc: 96.30% (Epoch 9)\n",
            "\n",
            "Epoch 11/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.53it/s, Loss=0.1124, Acc=96.42%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1124, Train Acc: 96.42%\n",
            "Val Loss: 0.1157, Val Acc: 96.27%\n",
            "Best Val Acc: 96.30% (Epoch 9)\n",
            "\n",
            "Epoch 12/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.24it/s, Loss=0.1005, Acc=96.77%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1005, Train Acc: 96.77%\n",
            "Val Loss: 0.1238, Val Acc: 96.11%\n",
            "Best Val Acc: 96.30% (Epoch 9)\n",
            "\n",
            "Epoch 13/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.66it/s, Loss=0.0861, Acc=97.28%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0861, Train Acc: 97.28%\n",
            "Val Loss: 0.1122, Val Acc: 96.50%\n",
            "Best Val Acc: 96.50% (Epoch 13)\n",
            "\n",
            "Epoch 14/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 49.10it/s, Loss=0.0720, Acc=97.69%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0720, Train Acc: 97.69%\n",
            "Val Loss: 0.0988, Val Acc: 96.92%\n",
            "Best Val Acc: 96.92% (Epoch 14)\n",
            "\n",
            "Epoch 15/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.73it/s, Loss=0.0601, Acc=98.07%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0601, Train Acc: 98.07%\n",
            "Val Loss: 0.0981, Val Acc: 96.95%\n",
            "Best Val Acc: 96.95% (Epoch 15)\n",
            "\n",
            "Epoch 16/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:18<00:00, 49.44it/s, Loss=0.0479, Acc=98.45%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0479, Train Acc: 98.45%\n",
            "Val Loss: 0.0960, Val Acc: 96.99%\n",
            "Best Val Acc: 96.99% (Epoch 16)\n",
            "\n",
            "Epoch 17/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:18<00:00, 50.19it/s, Loss=0.0394, Acc=98.78%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0394, Train Acc: 98.78%\n",
            "Val Loss: 0.0924, Val Acc: 97.06%\n",
            "Best Val Acc: 97.06% (Epoch 17)\n",
            "\n",
            "Epoch 18/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.80it/s, Loss=0.0352, Acc=98.94%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0352, Train Acc: 98.94%\n",
            "Val Loss: 0.0931, Val Acc: 97.05%\n",
            "Best Val Acc: 97.06% (Epoch 17)\n",
            "\n",
            "========================================\n",
            "EXPERIMENT COMPLETED: Small_MNIST2\n",
            "========================================\n",
            "Best Validation Accuracy: 97.06%\n",
            "Target Achievement (99.4%): ✗\n",
            "Parameter Efficiency (<20k): ✓\n"
          ]
        }
      ],
      "source": [
        "exp_config = {\n",
        "      'model_class': Small_MNIST3,\n",
        "      'model_name': 'Small_MNIST2',\n",
        "      'epochs': 18,\n",
        "      'learning_rate': 0.001,\n",
        "      'use_augmentation': False\n",
        "  }\n",
        "\n",
        "create_and_run(exp_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haI_fGWNkXGG"
      },
      "source": [
        "Train Accuracy - 98.94%\n",
        "Test Accuracy - 97.06%\n",
        "\n",
        "Let us apply GAP and see if there is an improvement. Also, trying and adding one more conv layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6YSwY_2kyOr"
      },
      "outputs": [],
      "source": [
        "class Small_MNIST4(nn.Module):\n",
        "    \"\"\"\n",
        "    Small CNN Architecture v1\n",
        "    - Basic efficient design with BN and Dropout\n",
        "    - Uses Global Average Pooling\n",
        "    - Target: <20k parameters, >99.4% accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dropout_rate=0.1):\n",
        "        super(Small_MNIST4, self).__init__()\n",
        "\n",
        "        # Feature extraction layers\n",
        "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(8, 16, 1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "\n",
        "        # Pooling and regularization\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(16, 16, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(16, 32, 1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(32, 32, 3)\n",
        "        # Final classification layer\n",
        "        self.conv6 = nn.Conv2d(32, 10, 3, padding=1)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # Block 3 & Classification\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.conv6(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oosXWgZ_lp4A",
        "outputId": "ecd605d1-b98b-432a-ac64-3bb805360f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              80\n",
            "       BatchNorm2d-2            [-1, 8, 28, 28]              16\n",
            "            Conv2d-3           [-1, 16, 30, 30]             144\n",
            "       BatchNorm2d-4           [-1, 16, 30, 30]              32\n",
            "         MaxPool2d-5           [-1, 16, 15, 15]               0\n",
            "            Conv2d-6           [-1, 16, 15, 15]           2,320\n",
            "       BatchNorm2d-7           [-1, 16, 15, 15]              32\n",
            "            Conv2d-8           [-1, 32, 17, 17]             544\n",
            "       BatchNorm2d-9           [-1, 32, 17, 17]              64\n",
            "        MaxPool2d-10             [-1, 32, 8, 8]               0\n",
            "           Conv2d-11             [-1, 32, 6, 6]           9,248\n",
            "           Conv2d-12             [-1, 10, 6, 6]           2,890\n",
            "AdaptiveAvgPool2d-13             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 15,370\n",
            "Trainable params: 15,370\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.57\n",
            "Params size (MB): 0.06\n",
            "Estimated Total Size (MB): 0.63\n",
            "----------------------------------------------------------------\n",
            "layer                          type   out_ch k         s         p         out(HxW)   RF(HxW)      jump     start       \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "conv1                          conv   8      3x3       1x1       1x1       28x28      3x3          1x1      0.50x0.50   \n",
            "conv2                          conv   16     1x1       1x1       1x1       30x30      3x3          1x1      -0.50x-0.50 \n",
            "pool1                          pool   -      2x2       2x2       0x0       15x15      4x4          2x2      0.00x0.00   \n",
            "conv3                          conv   16     3x3       1x1       1x1       15x15      8x8          2x2      0.00x0.00   \n",
            "conv4                          conv   32     1x1       1x1       1x1       17x17      8x8          2x2      -2.00x-2.00 \n",
            "pool2                          pool   -      2x2       2x2       0x0       8x8        10x10        4x4      -1.00x-1.00 \n",
            "conv5                          conv   32     3x3       1x1       0x0       6x6        18x18        4x4      3.00x3.00   \n",
            "conv6                          conv   10     3x3       1x1       1x1       6x6        26x26        4x4      3.00x3.00   \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Final output spatial size: 6 x 6\n",
            "Final receptive field: 26 x 26\n",
            "Final cumulative stride (jump): 4 x 4\n",
            "Center of top-left output unit relative to input pixel (0-index approx): 3.00 , 3.00\n"
          ]
        }
      ],
      "source": [
        "model_summary_and_rf(Small_MNIST4())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxtxXgAZoZO0",
        "outputId": "2ff0a7e4-71c0-4291-9074-915c4f8a77f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Experimental Suite: MNIST_CNN_20250914_143038\n",
            "Target: 99.4% accuracy with <20k parameters in <20 epochs\n",
            "\n",
            "============================================================\n",
            "Running Experiment: Small_MNIST2\n",
            "============================================================\n",
            "Using device: cuda\n",
            "\n",
            "Model Requirements Check:\n",
            "  Total Parameters: 15,370\n",
            "  Under 20k params: ✓\n",
            "  Has Batch Normalization: ✓\n",
            "  Has Dropout: ✗\n",
            "  Has Global Average Pooling: ✓\n",
            "  Has Fully Connected Layer: ✗\n",
            "\n",
            "Starting Training for 18 epochs...\n",
            "\n",
            "Epoch 1/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:18<00:00, 50.81it/s, Loss=0.6477, Acc=80.29%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6477, Train Acc: 80.29%\n",
            "Val Loss: 0.2071, Val Acc: 93.74%\n",
            "Best Val Acc: 93.74% (Epoch 1)\n",
            "\n",
            "Epoch 2/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 43.43it/s, Loss=0.1420, Acc=95.71%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1420, Train Acc: 95.71%\n",
            "Val Loss: 0.1331, Val Acc: 95.71%\n",
            "Best Val Acc: 95.71% (Epoch 2)\n",
            "\n",
            "Epoch 3/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.28it/s, Loss=0.1034, Acc=96.95%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1034, Train Acc: 96.95%\n",
            "Val Loss: 0.0858, Val Acc: 97.23%\n",
            "Best Val Acc: 97.23% (Epoch 3)\n",
            "\n",
            "Epoch 4/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.04it/s, Loss=0.0779, Acc=97.68%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0779, Train Acc: 97.68%\n",
            "Val Loss: 0.1065, Val Acc: 96.66%\n",
            "Best Val Acc: 97.23% (Epoch 3)\n",
            "\n",
            "Epoch 5/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.64it/s, Loss=0.0662, Acc=97.94%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0662, Train Acc: 97.94%\n",
            "Val Loss: 0.0639, Val Acc: 97.84%\n",
            "Best Val Acc: 97.84% (Epoch 5)\n",
            "\n",
            "Epoch 6/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 49.28it/s, Loss=0.0558, Acc=98.25%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0558, Train Acc: 98.25%\n",
            "Val Loss: 0.0680, Val Acc: 97.92%\n",
            "Best Val Acc: 97.92% (Epoch 6)\n",
            "\n",
            "Epoch 7/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.17it/s, Loss=0.0533, Acc=98.31%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0533, Train Acc: 98.31%\n",
            "Val Loss: 0.0401, Val Acc: 98.69%\n",
            "Best Val Acc: 98.69% (Epoch 7)\n",
            "\n",
            "Epoch 8/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.56it/s, Loss=0.0496, Acc=98.42%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0496, Train Acc: 98.42%\n",
            "Val Loss: 0.0472, Val Acc: 98.49%\n",
            "Best Val Acc: 98.69% (Epoch 7)\n",
            "\n",
            "Epoch 9/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:18<00:00, 49.57it/s, Loss=0.0477, Acc=98.53%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0477, Train Acc: 98.53%\n",
            "Val Loss: 0.0510, Val Acc: 98.44%\n",
            "Best Val Acc: 98.69% (Epoch 7)\n",
            "\n",
            "Epoch 10/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 46.94it/s, Loss=0.0438, Acc=98.61%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0438, Train Acc: 98.61%\n",
            "Val Loss: 0.0400, Val Acc: 98.69%\n",
            "Best Val Acc: 98.69% (Epoch 7)\n",
            "\n",
            "Epoch 11/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.69it/s, Loss=0.0374, Acc=98.86%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0374, Train Acc: 98.86%\n",
            "Val Loss: 0.0413, Val Acc: 98.75%\n",
            "Best Val Acc: 98.75% (Epoch 11)\n",
            "\n",
            "Epoch 12/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 49.16it/s, Loss=0.0328, Acc=98.99%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0328, Train Acc: 98.99%\n",
            "Val Loss: 0.0337, Val Acc: 99.00%\n",
            "Best Val Acc: 99.00% (Epoch 12)\n",
            "\n",
            "Epoch 13/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.80it/s, Loss=0.0280, Acc=99.14%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0280, Train Acc: 99.14%\n",
            "Val Loss: 0.0304, Val Acc: 99.04%\n",
            "Best Val Acc: 99.04% (Epoch 13)\n",
            "\n",
            "Epoch 14/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.48it/s, Loss=0.0212, Acc=99.32%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0212, Train Acc: 99.32%\n",
            "Val Loss: 0.0347, Val Acc: 98.88%\n",
            "Best Val Acc: 99.04% (Epoch 13)\n",
            "\n",
            "Epoch 15/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:18<00:00, 49.71it/s, Loss=0.0162, Acc=99.51%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0162, Train Acc: 99.51%\n",
            "Val Loss: 0.0227, Val Acc: 99.28%\n",
            "Best Val Acc: 99.28% (Epoch 15)\n",
            "\n",
            "Epoch 16/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 49.06it/s, Loss=0.0107, Acc=99.70%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0107, Train Acc: 99.70%\n",
            "Val Loss: 0.0242, Val Acc: 99.16%\n",
            "Best Val Acc: 99.28% (Epoch 15)\n",
            "\n",
            "Epoch 17/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.61it/s, Loss=0.0083, Acc=99.80%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0083, Train Acc: 99.80%\n",
            "Val Loss: 0.0233, Val Acc: 99.23%\n",
            "Best Val Acc: 99.28% (Epoch 15)\n",
            "\n",
            "Epoch 18/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:18<00:00, 50.35it/s, Loss=0.0067, Acc=99.88%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0067, Train Acc: 99.88%\n",
            "Val Loss: 0.0227, Val Acc: 99.24%\n",
            "Best Val Acc: 99.28% (Epoch 15)\n",
            "\n",
            "========================================\n",
            "EXPERIMENT COMPLETED: Small_MNIST2\n",
            "========================================\n",
            "Best Validation Accuracy: 99.28%\n",
            "Target Achievement (99.4%): ✗\n",
            "Parameter Efficiency (<20k): ✓\n"
          ]
        }
      ],
      "source": [
        "exp_config = {\n",
        "      'model_class': Small_MNIST4,\n",
        "      'model_name': 'Small_MNIST2',\n",
        "      'epochs': 18,\n",
        "      'learning_rate': 0.001,\n",
        "      'use_augmentation': False\n",
        "  }\n",
        "\n",
        "create_and_run(exp_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFHIvpb2qTu0"
      },
      "source": [
        "We are almost there\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "\n",
        "Train Accuracy - 99.88%\n",
        "Test Accuracy - 99.4%\n",
        "\n",
        "Let us add drop out and see if our accuracy gets better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJ_MDQpJqTK3"
      },
      "outputs": [],
      "source": [
        "class Small_MNIST5(nn.Module):\n",
        "    \"\"\"\n",
        "    Small CNN Architecture v1\n",
        "    - Basic efficient design with BN and Dropout\n",
        "    - Uses Global Average Pooling\n",
        "    - Target: <20k parameters, >99.4% accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dropout_rate=0.1):\n",
        "        super(Small_MNIST5, self).__init__()\n",
        "\n",
        "        # Feature extraction layers\n",
        "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(8, 16, 1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "\n",
        "        # Pooling and regularization\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.dropout1 = nn.Dropout2d(dropout_rate)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(16, 16, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(16, 32, 1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.dropout2 = nn.Dropout2d(dropout_rate * 1.5)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(32, 32, 3)\n",
        "        # Final classification layer\n",
        "        self.conv6 = nn.Conv2d(32, 10, 3, padding=1)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # Block 3 & Classification\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.conv6(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kticuj1FqmZf",
        "outputId": "4beb87bd-94ee-48a0-bad1-a9c3c5e4adb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              80\n",
            "       BatchNorm2d-2            [-1, 8, 28, 28]              16\n",
            "            Conv2d-3           [-1, 16, 30, 30]             144\n",
            "       BatchNorm2d-4           [-1, 16, 30, 30]              32\n",
            "         MaxPool2d-5           [-1, 16, 15, 15]               0\n",
            "         Dropout2d-6           [-1, 16, 15, 15]               0\n",
            "            Conv2d-7           [-1, 16, 15, 15]           2,320\n",
            "       BatchNorm2d-8           [-1, 16, 15, 15]              32\n",
            "            Conv2d-9           [-1, 32, 17, 17]             544\n",
            "      BatchNorm2d-10           [-1, 32, 17, 17]              64\n",
            "        MaxPool2d-11             [-1, 32, 8, 8]               0\n",
            "        Dropout2d-12             [-1, 32, 8, 8]               0\n",
            "           Conv2d-13             [-1, 32, 6, 6]           9,248\n",
            "           Conv2d-14             [-1, 10, 6, 6]           2,890\n",
            "AdaptiveAvgPool2d-15             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 15,370\n",
            "Trainable params: 15,370\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.61\n",
            "Params size (MB): 0.06\n",
            "Estimated Total Size (MB): 0.67\n",
            "----------------------------------------------------------------\n",
            "layer                          type   out_ch k         s         p         out(HxW)   RF(HxW)      jump     start       \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "conv1                          conv   8      3x3       1x1       1x1       28x28      3x3          1x1      0.50x0.50   \n",
            "conv2                          conv   16     1x1       1x1       1x1       30x30      3x3          1x1      -0.50x-0.50 \n",
            "pool1                          pool   -      2x2       2x2       0x0       15x15      4x4          2x2      0.00x0.00   \n",
            "conv3                          conv   16     3x3       1x1       1x1       15x15      8x8          2x2      0.00x0.00   \n",
            "conv4                          conv   32     1x1       1x1       1x1       17x17      8x8          2x2      -2.00x-2.00 \n",
            "pool2                          pool   -      2x2       2x2       0x0       8x8        10x10        4x4      -1.00x-1.00 \n",
            "conv5                          conv   32     3x3       1x1       0x0       6x6        18x18        4x4      3.00x3.00   \n",
            "conv6                          conv   10     3x3       1x1       1x1       6x6        26x26        4x4      3.00x3.00   \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Final output spatial size: 6 x 6\n",
            "Final receptive field: 26 x 26\n",
            "Final cumulative stride (jump): 4 x 4\n",
            "Center of top-left output unit relative to input pixel (0-index approx): 3.00 , 3.00\n"
          ]
        }
      ],
      "source": [
        "model_summary_and_rf(Small_MNIST5())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKj1Yaxgqqot",
        "outputId": "a8e1f3b0-7cf2-456e-faf8-88f7b682af7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Experimental Suite: MNIST_CNN_20250914_144204\n",
            "Target: 99.4% accuracy with <20k parameters in <20 epochs\n",
            "\n",
            "============================================================\n",
            "Running Experiment: Small_MNIST2\n",
            "============================================================\n",
            "Using device: cuda\n",
            "\n",
            "Model Requirements Check:\n",
            "  Total Parameters: 15,370\n",
            "  Under 20k params: ✓\n",
            "  Has Batch Normalization: ✓\n",
            "  Has Dropout: ✓\n",
            "  Has Global Average Pooling: ✓\n",
            "  Has Fully Connected Layer: ✗\n",
            "\n",
            "Starting Training for 18 epochs...\n",
            "\n",
            "Epoch 1/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.01it/s, Loss=0.7836, Acc=75.16%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7836, Train Acc: 75.16%\n",
            "Val Loss: 0.1546, Val Acc: 95.55%\n",
            "Best Val Acc: 95.55% (Epoch 1)\n",
            "\n",
            "Epoch 2/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.19it/s, Loss=0.1814, Acc=94.64%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1814, Train Acc: 94.64%\n",
            "Val Loss: 0.1419, Val Acc: 95.71%\n",
            "Best Val Acc: 95.71% (Epoch 2)\n",
            "\n",
            "Epoch 3/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 43.84it/s, Loss=0.1227, Acc=96.29%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1227, Train Acc: 96.29%\n",
            "Val Loss: 0.0564, Val Acc: 98.24%\n",
            "Best Val Acc: 98.24% (Epoch 3)\n",
            "\n",
            "Epoch 4/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.71it/s, Loss=0.0983, Acc=97.03%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0983, Train Acc: 97.03%\n",
            "Val Loss: 0.1043, Val Acc: 96.73%\n",
            "Best Val Acc: 98.24% (Epoch 3)\n",
            "\n",
            "Epoch 5/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.93it/s, Loss=0.0868, Acc=97.34%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0868, Train Acc: 97.34%\n",
            "Val Loss: 0.0701, Val Acc: 97.79%\n",
            "Best Val Acc: 98.24% (Epoch 3)\n",
            "\n",
            "Epoch 6/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.65it/s, Loss=0.0760, Acc=97.62%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0760, Train Acc: 97.62%\n",
            "Val Loss: 0.0447, Val Acc: 98.51%\n",
            "Best Val Acc: 98.51% (Epoch 6)\n",
            "\n",
            "Epoch 7/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.09it/s, Loss=0.0740, Acc=97.73%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0740, Train Acc: 97.73%\n",
            "Val Loss: 0.0515, Val Acc: 98.45%\n",
            "Best Val Acc: 98.51% (Epoch 6)\n",
            "\n",
            "Epoch 8/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.85it/s, Loss=0.0687, Acc=97.84%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0687, Train Acc: 97.84%\n",
            "Val Loss: 0.0472, Val Acc: 98.58%\n",
            "Best Val Acc: 98.58% (Epoch 8)\n",
            "\n",
            "Epoch 9/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.06it/s, Loss=0.0670, Acc=97.93%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0670, Train Acc: 97.93%\n",
            "Val Loss: 0.0550, Val Acc: 98.32%\n",
            "Best Val Acc: 98.58% (Epoch 8)\n",
            "\n",
            "Epoch 10/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.65it/s, Loss=0.0587, Acc=98.22%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0587, Train Acc: 98.22%\n",
            "Val Loss: 0.0438, Val Acc: 98.57%\n",
            "Best Val Acc: 98.58% (Epoch 8)\n",
            "\n",
            "Epoch 11/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.01it/s, Loss=0.0569, Acc=98.19%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0569, Train Acc: 98.19%\n",
            "Val Loss: 0.0457, Val Acc: 98.54%\n",
            "Best Val Acc: 98.58% (Epoch 8)\n",
            "\n",
            "Epoch 12/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.84it/s, Loss=0.0490, Acc=98.46%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0490, Train Acc: 98.46%\n",
            "Val Loss: 0.0344, Val Acc: 98.82%\n",
            "Best Val Acc: 98.82% (Epoch 12)\n",
            "\n",
            "Epoch 13/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.01it/s, Loss=0.0427, Acc=98.70%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0427, Train Acc: 98.70%\n",
            "Val Loss: 0.0266, Val Acc: 99.10%\n",
            "Best Val Acc: 99.10% (Epoch 13)\n",
            "\n",
            "Epoch 14/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.38it/s, Loss=0.0357, Acc=98.87%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0357, Train Acc: 98.87%\n",
            "Val Loss: 0.0280, Val Acc: 99.07%\n",
            "Best Val Acc: 99.10% (Epoch 13)\n",
            "\n",
            "Epoch 15/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 46.99it/s, Loss=0.0302, Acc=99.05%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0302, Train Acc: 99.05%\n",
            "Val Loss: 0.0264, Val Acc: 99.09%\n",
            "Best Val Acc: 99.10% (Epoch 13)\n",
            "\n",
            "Epoch 16/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.59it/s, Loss=0.0246, Acc=99.26%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0246, Train Acc: 99.26%\n",
            "Val Loss: 0.0218, Val Acc: 99.32%\n",
            "Best Val Acc: 99.32% (Epoch 16)\n",
            "\n",
            "Epoch 17/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.81it/s, Loss=0.0214, Acc=99.37%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0214, Train Acc: 99.37%\n",
            "Val Loss: 0.0206, Val Acc: 99.31%\n",
            "Best Val Acc: 99.32% (Epoch 16)\n",
            "\n",
            "Epoch 18/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.58it/s, Loss=0.0186, Acc=99.45%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0186, Train Acc: 99.45%\n",
            "Val Loss: 0.0204, Val Acc: 99.36%\n",
            "Best Val Acc: 99.36% (Epoch 18)\n",
            "\n",
            "========================================\n",
            "EXPERIMENT COMPLETED: Small_MNIST2\n",
            "========================================\n",
            "Best Validation Accuracy: 99.36%\n",
            "Target Achievement (99.4%): ✗\n",
            "Parameter Efficiency (<20k): ✓\n"
          ]
        }
      ],
      "source": [
        "exp_config = {\n",
        "      'model_class': Small_MNIST5,\n",
        "      'model_name': 'Small_MNIST2',\n",
        "      'epochs': 18,\n",
        "      'learning_rate': 0.001,\n",
        "      'use_augmentation': False\n",
        "  }\n",
        "\n",
        "create_and_run(exp_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuuJWYV1wsWH"
      },
      "source": [
        "Train Accuracy - 99.45%\n",
        "Test Accuracy - 99.36%\n",
        "\n",
        "Trying small changes in config with same architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoJE-Zp-qqu7",
        "outputId": "d542bcfb-a05a-4c95-8e3d-3679c6388868"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Experimental Suite: MNIST_CNN_20250914_151004\n",
            "Target: 99.4% accuracy with <20k parameters in <20 epochs\n",
            "\n",
            "============================================================\n",
            "Running Experiment: Small_MNIST6\n",
            "============================================================\n",
            "Using device: cuda\n",
            "\n",
            "Model Requirements Check:\n",
            "  Total Parameters: 15,370\n",
            "  Under 20k params: ✓\n",
            "  Has Batch Normalization: ✓\n",
            "  Has Dropout: ✓\n",
            "  Has Global Average Pooling: ✓\n",
            "  Has Fully Connected Layer: ✗\n",
            "\n",
            "Starting Training for 18 epochs...\n",
            "\n",
            "Epoch 1/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.93it/s, Loss=0.8887, Acc=71.19%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.8887, Train Acc: 71.19%\n",
            "Val Loss: 0.1884, Val Acc: 94.73%\n",
            "Best Val Acc: 94.73% (Epoch 1)\n",
            "\n",
            "Epoch 2/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.70it/s, Loss=0.2050, Acc=94.01%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2050, Train Acc: 94.01%\n",
            "Val Loss: 0.1160, Val Acc: 96.73%\n",
            "Best Val Acc: 96.73% (Epoch 2)\n",
            "\n",
            "Epoch 3/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 44.34it/s, Loss=0.1389, Acc=95.84%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1389, Train Acc: 95.84%\n",
            "Val Loss: 0.0861, Val Acc: 97.14%\n",
            "Best Val Acc: 97.14% (Epoch 3)\n",
            "\n",
            "Epoch 4/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.34it/s, Loss=0.1057, Acc=96.72%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1057, Train Acc: 96.72%\n",
            "Val Loss: 0.0549, Val Acc: 98.12%\n",
            "Best Val Acc: 98.12% (Epoch 4)\n",
            "\n",
            "Epoch 5/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 49.04it/s, Loss=0.0964, Acc=97.01%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0964, Train Acc: 97.01%\n",
            "Val Loss: 0.0656, Val Acc: 97.83%\n",
            "Best Val Acc: 98.12% (Epoch 4)\n",
            "\n",
            "Epoch 6/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.34it/s, Loss=0.0872, Acc=97.34%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0872, Train Acc: 97.34%\n",
            "Val Loss: 0.0563, Val Acc: 98.12%\n",
            "Best Val Acc: 98.12% (Epoch 4)\n",
            "\n",
            "Epoch 7/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.58it/s, Loss=0.0825, Acc=97.48%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0825, Train Acc: 97.48%\n",
            "Val Loss: 0.0691, Val Acc: 97.98%\n",
            "Best Val Acc: 98.12% (Epoch 4)\n",
            "\n",
            "Epoch 8/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 49.07it/s, Loss=0.0787, Acc=97.56%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0787, Train Acc: 97.56%\n",
            "Val Loss: 0.0426, Val Acc: 98.61%\n",
            "Best Val Acc: 98.61% (Epoch 8)\n",
            "\n",
            "Epoch 9/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.04it/s, Loss=0.0736, Acc=97.70%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0736, Train Acc: 97.70%\n",
            "Val Loss: 0.0404, Val Acc: 98.67%\n",
            "Best Val Acc: 98.67% (Epoch 9)\n",
            "\n",
            "Epoch 10/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.03it/s, Loss=0.0675, Acc=97.88%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0675, Train Acc: 97.88%\n",
            "Val Loss: 0.0537, Val Acc: 98.14%\n",
            "Best Val Acc: 98.67% (Epoch 9)\n",
            "\n",
            "Epoch 11/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:18<00:00, 49.70it/s, Loss=0.0623, Acc=98.10%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0623, Train Acc: 98.10%\n",
            "Val Loss: 0.0383, Val Acc: 98.75%\n",
            "Best Val Acc: 98.75% (Epoch 11)\n",
            "\n",
            "Epoch 12/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.58it/s, Loss=0.0556, Acc=98.29%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0556, Train Acc: 98.29%\n",
            "Val Loss: 0.0423, Val Acc: 98.68%\n",
            "Best Val Acc: 98.75% (Epoch 11)\n",
            "\n",
            "Epoch 13/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.75it/s, Loss=0.0493, Acc=98.46%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0493, Train Acc: 98.46%\n",
            "Val Loss: 0.0339, Val Acc: 98.90%\n",
            "Best Val Acc: 98.90% (Epoch 13)\n",
            "\n",
            "Epoch 14/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.41it/s, Loss=0.0419, Acc=98.75%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0419, Train Acc: 98.75%\n",
            "Val Loss: 0.0255, Val Acc: 99.13%\n",
            "Best Val Acc: 99.13% (Epoch 14)\n",
            "\n",
            "Epoch 15/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 49.21it/s, Loss=0.0348, Acc=98.89%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0348, Train Acc: 98.89%\n",
            "Val Loss: 0.0253, Val Acc: 99.21%\n",
            "Best Val Acc: 99.21% (Epoch 15)\n",
            "\n",
            "Epoch 16/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.08it/s, Loss=0.0276, Acc=99.17%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0276, Train Acc: 99.17%\n",
            "Val Loss: 0.0225, Val Acc: 99.18%\n",
            "Best Val Acc: 99.21% (Epoch 15)\n",
            "\n",
            "Epoch 17/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:18<00:00, 49.40it/s, Loss=0.0249, Acc=99.26%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0249, Train Acc: 99.26%\n",
            "Val Loss: 0.0215, Val Acc: 99.20%\n",
            "Best Val Acc: 99.21% (Epoch 15)\n",
            "\n",
            "Epoch 18/18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 49.31it/s, Loss=0.0214, Acc=99.35%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0214, Train Acc: 99.35%\n",
            "Val Loss: 0.0208, Val Acc: 99.24%\n",
            "Best Val Acc: 99.24% (Epoch 18)\n",
            "\n",
            "========================================\n",
            "EXPERIMENT COMPLETED: Small_MNIST6\n",
            "========================================\n",
            "Best Validation Accuracy: 99.24%\n",
            "Target Achievement (99.4%): ✗\n",
            "Parameter Efficiency (<20k): ✓\n"
          ]
        }
      ],
      "source": [
        "exp_config = {\n",
        "      'model_class': Small_MNIST5,\n",
        "      'model_name': 'Small_MNIST6',\n",
        "      'epochs': 18,\n",
        "      'learning_rate': 0.001,\n",
        "      'scheduler_type': 'onecycle',\n",
        "      'use_augmentation': True,\n",
        "      'dropout_rate': 0.15\n",
        "  }\n",
        "\n",
        "create_and_run(exp_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsCVNZUL3P3M"
      },
      "source": [
        "Making it 19 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9XcM4AWLwrfc",
        "outputId": "21a02459-957a-4ce3-f7cb-94ced34ced7a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">noble-shape-6</strong> at: <a href='https://wandb.ai/johnced/cnn_mnist/runs/uvm3wgbt' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist/runs/uvm3wgbt</a><br> View project at: <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250914_152224-uvm3wgbt/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for wandb.init()..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250914_152332-a0504s3q</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/johnced/cnn_mnist/runs/a0504s3q' target=\"_blank\">proud-lion-7</a></strong> to <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/johnced/cnn_mnist/runs/a0504s3q' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist/runs/a0504s3q</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Experimental Suite: MNIST_CNN_20250914_152335\n",
            "Target: 99.4% accuracy with <20k parameters in <20 epochs\n",
            "\n",
            "============================================================\n",
            "Running Experiment: Small_MNIST6\n",
            "============================================================\n",
            "Using device: cuda\n",
            "\n",
            "Model Requirements Check:\n",
            "  Total Parameters: 15,370\n",
            "  Under 20k params: ✓\n",
            "  Has Batch Normalization: ✓\n",
            "  Has Dropout: ✓\n",
            "  Has Global Average Pooling: ✓\n",
            "  Has Fully Connected Layer: ✗\n",
            "\n",
            "Starting Training for 19 epochs...\n",
            "\n",
            "Epoch 1/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.63it/s, Loss=0.8394, Acc=73.09%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.8394, Train Acc: 73.09%\n",
            "Val Loss: 0.1757, Val Acc: 94.92%\n",
            "Best Val Acc: 94.92% (Epoch 1)\n",
            "\n",
            "Epoch 2/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.47it/s, Loss=0.2017, Acc=93.90%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2017, Train Acc: 93.90%\n",
            "Val Loss: 0.1453, Val Acc: 95.54%\n",
            "Best Val Acc: 95.54% (Epoch 2)\n",
            "\n",
            "Epoch 3/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 44.03it/s, Loss=0.1450, Acc=95.64%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1450, Train Acc: 95.64%\n",
            "Val Loss: 0.0764, Val Acc: 97.62%\n",
            "Best Val Acc: 97.62% (Epoch 3)\n",
            "\n",
            "Epoch 4/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.37it/s, Loss=0.1155, Acc=96.52%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1155, Train Acc: 96.52%\n",
            "Val Loss: 0.0820, Val Acc: 97.53%\n",
            "Best Val Acc: 97.62% (Epoch 3)\n",
            "\n",
            "Epoch 5/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.67it/s, Loss=0.1031, Acc=96.81%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1031, Train Acc: 96.81%\n",
            "Val Loss: 0.0787, Val Acc: 97.50%\n",
            "Best Val Acc: 97.62% (Epoch 3)\n",
            "\n",
            "Epoch 6/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.07it/s, Loss=0.0925, Acc=97.13%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0925, Train Acc: 97.13%\n",
            "Val Loss: 0.0475, Val Acc: 98.46%\n",
            "Best Val Acc: 98.46% (Epoch 6)\n",
            "\n",
            "Epoch 7/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 49.25it/s, Loss=0.0854, Acc=97.41%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0854, Train Acc: 97.41%\n",
            "Val Loss: 0.0597, Val Acc: 98.32%\n",
            "Best Val Acc: 98.46% (Epoch 6)\n",
            "\n",
            "Epoch 8/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.13it/s, Loss=0.0805, Acc=97.59%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0805, Train Acc: 97.59%\n",
            "Val Loss: 0.0488, Val Acc: 98.46%\n",
            "Best Val Acc: 98.46% (Epoch 6)\n",
            "\n",
            "Epoch 9/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.35it/s, Loss=0.0747, Acc=97.72%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0747, Train Acc: 97.72%\n",
            "Val Loss: 0.0403, Val Acc: 98.73%\n",
            "Best Val Acc: 98.73% (Epoch 9)\n",
            "\n",
            "Epoch 10/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:18<00:00, 49.49it/s, Loss=0.0709, Acc=97.89%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0709, Train Acc: 97.89%\n",
            "Val Loss: 0.0454, Val Acc: 98.63%\n",
            "Best Val Acc: 98.73% (Epoch 9)\n",
            "\n",
            "Epoch 11/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.01it/s, Loss=0.0676, Acc=97.89%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0676, Train Acc: 97.89%\n",
            "Val Loss: 0.0367, Val Acc: 98.83%\n",
            "Best Val Acc: 98.83% (Epoch 11)\n",
            "\n",
            "Epoch 12/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.52it/s, Loss=0.0588, Acc=98.11%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0588, Train Acc: 98.11%\n",
            "Val Loss: 0.0325, Val Acc: 98.83%\n",
            "Best Val Acc: 98.83% (Epoch 11)\n",
            "\n",
            "Epoch 13/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:18<00:00, 49.61it/s, Loss=0.0538, Acc=98.33%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0538, Train Acc: 98.33%\n",
            "Val Loss: 0.0378, Val Acc: 98.80%\n",
            "Best Val Acc: 98.83% (Epoch 11)\n",
            "\n",
            "Epoch 14/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.55it/s, Loss=0.0482, Acc=98.44%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0482, Train Acc: 98.44%\n",
            "Val Loss: 0.0322, Val Acc: 98.95%\n",
            "Best Val Acc: 98.95% (Epoch 14)\n",
            "\n",
            "Epoch 15/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.92it/s, Loss=0.0402, Acc=98.72%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0402, Train Acc: 98.72%\n",
            "Val Loss: 0.0280, Val Acc: 99.18%\n",
            "Best Val Acc: 99.18% (Epoch 15)\n",
            "\n",
            "Epoch 16/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:18<00:00, 49.87it/s, Loss=0.0331, Acc=98.99%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0331, Train Acc: 98.99%\n",
            "Val Loss: 0.0233, Val Acc: 99.30%\n",
            "Best Val Acc: 99.30% (Epoch 16)\n",
            "\n",
            "Epoch 17/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 49.22it/s, Loss=0.0281, Acc=99.12%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0281, Train Acc: 99.12%\n",
            "Val Loss: 0.0222, Val Acc: 99.28%\n",
            "Best Val Acc: 99.30% (Epoch 16)\n",
            "\n",
            "Epoch 18/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 48.13it/s, Loss=0.0241, Acc=99.26%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0241, Train Acc: 99.26%\n",
            "Val Loss: 0.0204, Val Acc: 99.34%\n",
            "Best Val Acc: 99.34% (Epoch 18)\n",
            "\n",
            "Epoch 19/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:18<00:00, 50.34it/s, Loss=0.0220, Acc=99.33%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0220, Train Acc: 99.33%\n",
            "Val Loss: 0.0203, Val Acc: 99.37%\n",
            "Best Val Acc: 99.37% (Epoch 19)\n",
            "\n",
            "========================================\n",
            "EXPERIMENT COMPLETED: Small_MNIST6\n",
            "========================================\n",
            "Best Validation Accuracy: 99.37%\n",
            "Target Achievement (99.4%): ✗\n",
            "Parameter Efficiency (<20k): ✓\n"
          ]
        }
      ],
      "source": [
        "exp_config = {\n",
        "      'model_class': Small_MNIST5,\n",
        "      'model_name': 'Small_MNIST6',\n",
        "      'epochs': 19,\n",
        "      'learning_rate': 0.001,\n",
        "      'scheduler_type': 'onecycle',\n",
        "      'use_augmentation': True,\n",
        "      'dropout_rate': 0.15\n",
        "  }\n",
        "\n",
        "wandb.init(project=\"cnn_mnist\", config=exp_config)\n",
        "cfg = wandb.config\n",
        "\n",
        "# ------------------------------\n",
        "# Data loaders (MNIST)\n",
        "# ------------------------------\n",
        "torch.manual_seed(42)\n",
        "\n",
        "create_and_run(exp_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJoZb6-z3Vnj"
      },
      "source": [
        "Train accuracy - 99.33%\n",
        "Test accuracy - 99.37%\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMv8pHt6j8o3"
      },
      "source": [
        "Changing architecture slightly to add more 1x1 conv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2uiAJ6mj9ut"
      },
      "outputs": [],
      "source": [
        "class Small_MNIST8(nn.Module):\n",
        "    \"\"\"\n",
        "    Small CNN Architecture v1\n",
        "    - Basic efficient design with BN and Dropout\n",
        "    - Uses Global Average Pooling\n",
        "    - Target: <20k parameters, >99.4% accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dropout_rate=0.1):\n",
        "        super(Small_MNIST8, self).__init__()\n",
        "\n",
        "        # Feature extraction layers\n",
        "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(8, 16, 1)\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "\n",
        "        # Pooling and regularization\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.dropout1 = nn.Dropout2d(dropout_rate)\n",
        "\n",
        "        self.conv1_1 = nn.Conv2d(16, 16, 3, padding=1)\n",
        "        self.bn1_1 = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(16, 16, 1)\n",
        "        self.bn2_1 = nn.BatchNorm2d(16)\n",
        "\n",
        "        # Pooling and regularization\n",
        "        self.pool1_1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.dropout1_1 = nn.Dropout2d(dropout_rate)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(32, 64, 1)\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "\n",
        "        #self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.dropout2 = nn.Dropout2d(dropout_rate * 1.5)\n",
        "\n",
        "        #self.conv5 = nn.Conv2d(64, 64, 3)\n",
        "        # Final classification layer\n",
        "        self.conv6 = nn.Conv2d(64, 10, 3, padding=1)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # Block 1_1\n",
        "        x = F.relu(self.bn1_1(self.conv1_1(x)))\n",
        "        x = F.relu(self.bn2_1(self.conv2_1(x)))\n",
        "        x = self.pool1_1(x)\n",
        "        x = self.dropout1_1(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        #x = self.pool2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # Block 3 & Classification\n",
        "        #x = F.relu(self.conv5(x))\n",
        "        x = self.conv6(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcKq9etWlyau",
        "outputId": "3e73a8b6-c341-4c6d-f9bb-f26aac69ac70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              80\n",
            "       BatchNorm2d-2            [-1, 8, 28, 28]              16\n",
            "            Conv2d-3           [-1, 16, 28, 28]             144\n",
            "       BatchNorm2d-4           [-1, 16, 28, 28]              32\n",
            "         MaxPool2d-5           [-1, 16, 14, 14]               0\n",
            "         Dropout2d-6           [-1, 16, 14, 14]               0\n",
            "            Conv2d-7           [-1, 16, 14, 14]           2,320\n",
            "       BatchNorm2d-8           [-1, 16, 14, 14]              32\n",
            "            Conv2d-9           [-1, 16, 14, 14]             272\n",
            "      BatchNorm2d-10           [-1, 16, 14, 14]              32\n",
            "        MaxPool2d-11             [-1, 16, 7, 7]               0\n",
            "        Dropout2d-12             [-1, 16, 7, 7]               0\n",
            "           Conv2d-13             [-1, 32, 7, 7]           4,640\n",
            "      BatchNorm2d-14             [-1, 32, 7, 7]              64\n",
            "           Conv2d-15             [-1, 64, 7, 7]           2,112\n",
            "      BatchNorm2d-16             [-1, 64, 7, 7]             128\n",
            "        Dropout2d-17             [-1, 64, 7, 7]               0\n",
            "           Conv2d-18             [-1, 10, 7, 7]           5,770\n",
            "AdaptiveAvgPool2d-19             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 15,642\n",
            "Trainable params: 15,642\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.54\n",
            "Params size (MB): 0.06\n",
            "Estimated Total Size (MB): 0.60\n",
            "----------------------------------------------------------------\n",
            "layer                          type   out_ch k         s         p         out(HxW)   RF(HxW)      jump     start       \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "conv1                          conv   8      3x3       1x1       1x1       28x28      3x3          1x1      0.50x0.50   \n",
            "conv2                          conv   16     1x1       1x1       0x0       28x28      3x3          1x1      0.50x0.50   \n",
            "pool1                          pool   -      2x2       2x2       0x0       14x14      4x4          2x2      1.00x1.00   \n",
            "conv1_1                        conv   16     3x3       1x1       1x1       14x14      8x8          2x2      1.00x1.00   \n",
            "conv2_1                        conv   16     1x1       1x1       0x0       14x14      8x8          2x2      1.00x1.00   \n",
            "pool1_1                        pool   -      2x2       2x2       0x0       7x7        10x10        4x4      2.00x2.00   \n",
            "conv3                          conv   32     3x3       1x1       1x1       7x7        18x18        4x4      2.00x2.00   \n",
            "conv4                          conv   64     1x1       1x1       0x0       7x7        18x18        4x4      2.00x2.00   \n",
            "conv6                          conv   10     3x3       1x1       1x1       7x7        26x26        4x4      2.00x2.00   \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Final output spatial size: 7 x 7\n",
            "Final receptive field: 26 x 26\n",
            "Final cumulative stride (jump): 4 x 4\n",
            "Center of top-left output unit relative to input pixel (0-index approx): 2.00 , 2.00\n"
          ]
        }
      ],
      "source": [
        "model_summary_and_rf(Small_MNIST8())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rq6GBVkYlyhS",
        "outputId": "eb15a2d0-2d6e-4390-e2e1-2ba75619f913"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇█▇█████</td></tr><tr><td>test_loss</td><td>█▄▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁</td></tr><tr><td>train/epoch_acc</td><td>▁▆▇▇▇▇▇████████████</td></tr><tr><td>train/epoch_loss</td><td>█▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>99.33</td></tr><tr><td>test_loss</td><td>0.01942</td></tr><tr><td>train/epoch_acc</td><td>98.78</td></tr><tr><td>train/epoch_loss</td><td>0.03999</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">light-firebrand-17</strong> at: <a href='https://wandb.ai/johnced/cnn_mnist/runs/4ou918zl' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist/runs/4ou918zl</a><br> View project at: <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250914_185909-4ou918zl/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "creating run (0.0s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250914_191129-xx3b5sg6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/johnced/cnn_mnist/runs/xx3b5sg6' target=\"_blank\">spring-microwave-18</a></strong> to <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/johnced/cnn_mnist/runs/xx3b5sg6' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist/runs/xx3b5sg6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Experimental Suite: MNIST_CNN_20250914_191131\n",
            "Target: 99.4% accuracy with <20k parameters in <20 epochs\n",
            "\n",
            "============================================================\n",
            "Running Experiment: Small_MNIST8\n",
            "============================================================\n",
            "Using device: cuda\n",
            "\n",
            "Model Requirements Check:\n",
            "  Total Parameters: 15,642\n",
            "  Under 20k params: ✓\n",
            "  Has Batch Normalization: ✓\n",
            "  Has Dropout: ✓\n",
            "  Has Global Average Pooling: ✓\n",
            "  Has Fully Connected Layer: ✗\n",
            "\n",
            "Starting Training for 19 epochs...\n",
            "\n",
            "Epoch 1/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:23<00:00, 40.76it/s, Loss=0.9762, Acc=68.58%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.9762, Train Acc: 68.58%\n",
            "Val Loss: 0.1988, Val Acc: 94.41%\n",
            "Best Val Acc: 94.41% (Epoch 1)\n",
            "\n",
            "Epoch 2/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 44.37it/s, Loss=0.2699, Acc=91.83%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2699, Train Acc: 91.83%\n",
            "Val Loss: 0.0917, Val Acc: 97.12%\n",
            "Best Val Acc: 97.12% (Epoch 2)\n",
            "\n",
            "Epoch 3/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 44.54it/s, Loss=0.1787, Acc=94.64%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1787, Train Acc: 94.64%\n",
            "Val Loss: 0.0696, Val Acc: 97.77%\n",
            "Best Val Acc: 97.77% (Epoch 3)\n",
            "\n",
            "Epoch 4/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 44.94it/s, Loss=0.1397, Acc=95.80%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1397, Train Acc: 95.80%\n",
            "Val Loss: 0.0777, Val Acc: 97.63%\n",
            "Best Val Acc: 97.77% (Epoch 3)\n",
            "\n",
            "Epoch 5/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 44.30it/s, Loss=0.1276, Acc=96.16%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1276, Train Acc: 96.16%\n",
            "Val Loss: 0.0605, Val Acc: 98.03%\n",
            "Best Val Acc: 98.03% (Epoch 5)\n",
            "\n",
            "Epoch 6/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.11it/s, Loss=0.1192, Acc=96.33%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1192, Train Acc: 96.33%\n",
            "Val Loss: 0.0476, Val Acc: 98.51%\n",
            "Best Val Acc: 98.51% (Epoch 6)\n",
            "\n",
            "Epoch 7/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 44.73it/s, Loss=0.1109, Acc=96.65%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1109, Train Acc: 96.65%\n",
            "Val Loss: 0.0465, Val Acc: 98.57%\n",
            "Best Val Acc: 98.57% (Epoch 7)\n",
            "\n",
            "Epoch 8/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 43.96it/s, Loss=0.1072, Acc=96.84%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1072, Train Acc: 96.84%\n",
            "Val Loss: 0.0496, Val Acc: 98.38%\n",
            "Best Val Acc: 98.57% (Epoch 7)\n",
            "\n",
            "Epoch 9/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 44.51it/s, Loss=0.0992, Acc=97.00%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0992, Train Acc: 97.00%\n",
            "Val Loss: 0.0483, Val Acc: 98.49%\n",
            "Best Val Acc: 98.57% (Epoch 7)\n",
            "\n",
            "Epoch 10/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.78it/s, Loss=0.0933, Acc=97.14%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0933, Train Acc: 97.14%\n",
            "Val Loss: 0.0397, Val Acc: 98.78%\n",
            "Best Val Acc: 98.78% (Epoch 10)\n",
            "\n",
            "Epoch 11/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.57it/s, Loss=0.0877, Acc=97.35%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0877, Train Acc: 97.35%\n",
            "Val Loss: 0.0398, Val Acc: 98.75%\n",
            "Best Val Acc: 98.78% (Epoch 10)\n",
            "\n",
            "Epoch 12/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 42.82it/s, Loss=0.0819, Acc=97.50%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0819, Train Acc: 97.50%\n",
            "Val Loss: 0.0407, Val Acc: 98.70%\n",
            "Best Val Acc: 98.78% (Epoch 10)\n",
            "\n",
            "Epoch 13/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:22<00:00, 42.55it/s, Loss=0.0745, Acc=97.76%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0745, Train Acc: 97.76%\n",
            "Val Loss: 0.0316, Val Acc: 99.00%\n",
            "Best Val Acc: 99.00% (Epoch 13)\n",
            "\n",
            "Epoch 14/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:22<00:00, 41.75it/s, Loss=0.0672, Acc=97.97%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0672, Train Acc: 97.97%\n",
            "Val Loss: 0.0373, Val Acc: 98.77%\n",
            "Best Val Acc: 99.00% (Epoch 13)\n",
            "\n",
            "Epoch 15/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 43.52it/s, Loss=0.0596, Acc=98.19%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0596, Train Acc: 98.19%\n",
            "Val Loss: 0.0258, Val Acc: 99.17%\n",
            "Best Val Acc: 99.17% (Epoch 15)\n",
            "\n",
            "Epoch 16/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.15it/s, Loss=0.0487, Acc=98.60%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0487, Train Acc: 98.60%\n",
            "Val Loss: 0.0249, Val Acc: 99.19%\n",
            "Best Val Acc: 99.19% (Epoch 16)\n",
            "\n",
            "Epoch 17/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.40it/s, Loss=0.0456, Acc=98.62%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0456, Train Acc: 98.62%\n",
            "Val Loss: 0.0233, Val Acc: 99.24%\n",
            "Best Val Acc: 99.24% (Epoch 17)\n",
            "\n",
            "Epoch 18/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 43.59it/s, Loss=0.0413, Acc=98.78%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0413, Train Acc: 98.78%\n",
            "Val Loss: 0.0227, Val Acc: 99.26%\n",
            "Best Val Acc: 99.26% (Epoch 18)\n",
            "\n",
            "Epoch 19/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:22<00:00, 41.91it/s, Loss=0.0403, Acc=98.78%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0403, Train Acc: 98.78%\n",
            "Val Loss: 0.0222, Val Acc: 99.28%\n",
            "Best Val Acc: 99.28% (Epoch 19)\n",
            "\n",
            "========================================\n",
            "EXPERIMENT COMPLETED: Small_MNIST8\n",
            "========================================\n",
            "Best Validation Accuracy: 99.28%\n",
            "Target Achievement (99.4%): ✗\n",
            "Parameter Efficiency (<20k): ✓\n"
          ]
        }
      ],
      "source": [
        "exp_config = {\n",
        "      'model_class': Small_MNIST8,\n",
        "      'model_name': 'Small_MNIST8',\n",
        "      'epochs': 19,\n",
        "      'learning_rate': 0.001,\n",
        "      'scheduler_type': 'onecycle',\n",
        "      'use_augmentation': True,\n",
        "      'dropout_rate': 0.15\n",
        "  }\n",
        "\n",
        "wandb.init(project=\"cnn_mnist\", config=exp_config)\n",
        "cfg = wandb.config\n",
        "\n",
        "# ------------------------------\n",
        "# Data loaders (MNIST)\n",
        "# ------------------------------\n",
        "torch.manual_seed(42)\n",
        "\n",
        "create_and_run(exp_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxqCen6nmHLp"
      },
      "source": [
        "Trying groups (depth-wise and point-wise) architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxGd964DmIIc"
      },
      "outputs": [],
      "source": [
        "class Small_MNIST10(nn.Module):\n",
        "    \"\"\"\n",
        "    Small CNN Architecture v1\n",
        "    - Basic efficient design with BN and Dropout\n",
        "    - Uses Global Average Pooling\n",
        "    - Target: <20k parameters, >99.4% accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dropout_rate=0.1):\n",
        "        super(Small_MNIST10, self).__init__()\n",
        "\n",
        "        # Feature extraction layers\n",
        "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(8, 16, 1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "\n",
        "        # Pooling and regularization\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.dropout1 = nn.Dropout2d(dropout_rate)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(32, 64, 1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.dropout2 = nn.Dropout2d(dropout_rate * 1.5)\n",
        "\n",
        "        self.conv5_dw = nn.Conv2d(64, 64, 3, padding=1, groups=64, bias=False)\n",
        "        self.conv5_pw = nn.Conv2d(64, 64, 1, bias=False)\n",
        "        self.bn5 = nn.BatchNorm2d(64)\n",
        "        # Final classification layer\n",
        "        self.conv6 = nn.Conv2d(64, 10, 3, padding=1)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # Block 3 & Classification\n",
        "        x = self.conv5_dw(x)\n",
        "        x = self.conv5_pw(x)\n",
        "        x = F.relu(self.bn5(x))\n",
        "        x = self.conv6(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i3EAjnnmPSf",
        "outputId": "944a0aa0-a636-4c2c-b95a-be04da0bf4d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              80\n",
            "       BatchNorm2d-2            [-1, 8, 28, 28]              16\n",
            "            Conv2d-3           [-1, 16, 30, 30]             144\n",
            "       BatchNorm2d-4           [-1, 16, 30, 30]              32\n",
            "         MaxPool2d-5           [-1, 16, 15, 15]               0\n",
            "         Dropout2d-6           [-1, 16, 15, 15]               0\n",
            "            Conv2d-7           [-1, 32, 15, 15]           4,640\n",
            "       BatchNorm2d-8           [-1, 32, 15, 15]              64\n",
            "            Conv2d-9           [-1, 64, 17, 17]           2,112\n",
            "      BatchNorm2d-10           [-1, 64, 17, 17]             128\n",
            "        MaxPool2d-11             [-1, 64, 8, 8]               0\n",
            "        Dropout2d-12             [-1, 64, 8, 8]               0\n",
            "           Conv2d-13             [-1, 64, 8, 8]             576\n",
            "           Conv2d-14             [-1, 64, 8, 8]           4,096\n",
            "      BatchNorm2d-15             [-1, 64, 8, 8]             128\n",
            "           Conv2d-16             [-1, 10, 8, 8]           5,770\n",
            "AdaptiveAvgPool2d-17             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 17,786\n",
            "Trainable params: 17,786\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.92\n",
            "Params size (MB): 0.07\n",
            "Estimated Total Size (MB): 0.99\n",
            "----------------------------------------------------------------\n",
            "layer                          type   out_ch k         s         p         out(HxW)   RF(HxW)      jump     start       \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "conv1                          conv   8      3x3       1x1       1x1       28x28      3x3          1x1      0.50x0.50   \n",
            "conv2                          conv   16     1x1       1x1       1x1       30x30      3x3          1x1      -0.50x-0.50 \n",
            "pool1                          pool   -      2x2       2x2       0x0       15x15      4x4          2x2      0.00x0.00   \n",
            "conv3                          conv   32     3x3       1x1       1x1       15x15      8x8          2x2      0.00x0.00   \n",
            "conv4                          conv   64     1x1       1x1       1x1       17x17      8x8          2x2      -2.00x-2.00 \n",
            "pool2                          pool   -      2x2       2x2       0x0       8x8        10x10        4x4      -1.00x-1.00 \n",
            "conv5_dw                       conv   64     3x3       1x1       1x1       8x8        18x18        4x4      -1.00x-1.00 \n",
            "conv5_pw                       conv   64     1x1       1x1       0x0       8x8        18x18        4x4      -1.00x-1.00 \n",
            "conv6                          conv   10     3x3       1x1       1x1       8x8        26x26        4x4      -1.00x-1.00 \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Final output spatial size: 8 x 8\n",
            "Final receptive field: 26 x 26\n",
            "Final cumulative stride (jump): 4 x 4\n",
            "Center of top-left output unit relative to input pixel (0-index approx): -1.00 , -1.00\n"
          ]
        }
      ],
      "source": [
        "model_summary_and_rf(Small_MNIST10())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0yDd1fRxmPWq",
        "outputId": "ef784201-daea-4b2a-eeb0-ee936a9bf05d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇█▇█████</td></tr><tr><td>test_loss</td><td>█▄▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁</td></tr><tr><td>train/epoch_acc</td><td>▁▆▇▇▇▇█████████████</td></tr><tr><td>train/epoch_loss</td><td>█▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>99.28</td></tr><tr><td>test_loss</td><td>0.02219</td></tr><tr><td>train/epoch_acc</td><td>98.77667</td></tr><tr><td>train/epoch_loss</td><td>0.04025</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">spring-microwave-18</strong> at: <a href='https://wandb.ai/johnced/cnn_mnist/runs/xx3b5sg6' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist/runs/xx3b5sg6</a><br> View project at: <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250914_191129-xx3b5sg6/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "creating run (0.0s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250914_192054-2m30gpmr</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/johnced/cnn_mnist/runs/2m30gpmr' target=\"_blank\">swift-firebrand-19</a></strong> to <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/johnced/cnn_mnist/runs/2m30gpmr' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist/runs/2m30gpmr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Experimental Suite: MNIST_CNN_20250914_192056\n",
            "Target: 99.4% accuracy with <20k parameters in <20 epochs\n",
            "\n",
            "============================================================\n",
            "Running Experiment: Small_MNIST10\n",
            "============================================================\n",
            "Using device: cuda\n",
            "\n",
            "Model Requirements Check:\n",
            "  Total Parameters: 17,786\n",
            "  Under 20k params: ✓\n",
            "  Has Batch Normalization: ✓\n",
            "  Has Dropout: ✓\n",
            "  Has Global Average Pooling: ✓\n",
            "  Has Fully Connected Layer: ✗\n",
            "\n",
            "Starting Training for 19 epochs...\n",
            "\n",
            "Epoch 1/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.75it/s, Loss=1.0983, Acc=64.33%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.0983, Train Acc: 64.33%\n",
            "Val Loss: 0.2132, Val Acc: 94.91%\n",
            "Best Val Acc: 94.91% (Epoch 1)\n",
            "\n",
            "Epoch 2/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 44.57it/s, Loss=0.2280, Acc=93.59%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2280, Train Acc: 93.59%\n",
            "Val Loss: 0.1135, Val Acc: 96.61%\n",
            "Best Val Acc: 96.61% (Epoch 2)\n",
            "\n",
            "Epoch 3/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 42.93it/s, Loss=0.1480, Acc=95.54%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1480, Train Acc: 95.54%\n",
            "Val Loss: 0.1061, Val Acc: 96.62%\n",
            "Best Val Acc: 96.62% (Epoch 3)\n",
            "\n",
            "Epoch 4/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.61it/s, Loss=0.1250, Acc=96.20%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1250, Train Acc: 96.20%\n",
            "Val Loss: 0.0692, Val Acc: 97.89%\n",
            "Best Val Acc: 97.89% (Epoch 4)\n",
            "\n",
            "Epoch 5/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.04it/s, Loss=0.1092, Acc=96.68%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1092, Train Acc: 96.68%\n",
            "Val Loss: 0.0672, Val Acc: 97.97%\n",
            "Best Val Acc: 97.97% (Epoch 5)\n",
            "\n",
            "Epoch 6/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.29it/s, Loss=0.1011, Acc=96.89%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1011, Train Acc: 96.89%\n",
            "Val Loss: 0.0411, Val Acc: 98.78%\n",
            "Best Val Acc: 98.78% (Epoch 6)\n",
            "\n",
            "Epoch 7/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.60it/s, Loss=0.0894, Acc=97.27%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0894, Train Acc: 97.27%\n",
            "Val Loss: 0.0477, Val Acc: 98.56%\n",
            "Best Val Acc: 98.78% (Epoch 6)\n",
            "\n",
            "Epoch 8/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 44.91it/s, Loss=0.0867, Acc=97.31%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0867, Train Acc: 97.31%\n",
            "Val Loss: 0.0462, Val Acc: 98.54%\n",
            "Best Val Acc: 98.78% (Epoch 6)\n",
            "\n",
            "Epoch 9/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 46.99it/s, Loss=0.0819, Acc=97.54%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0819, Train Acc: 97.54%\n",
            "Val Loss: 0.0412, Val Acc: 98.67%\n",
            "Best Val Acc: 98.78% (Epoch 6)\n",
            "\n",
            "Epoch 10/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 44.28it/s, Loss=0.0769, Acc=97.74%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0769, Train Acc: 97.74%\n",
            "Val Loss: 0.0419, Val Acc: 98.56%\n",
            "Best Val Acc: 98.78% (Epoch 6)\n",
            "\n",
            "Epoch 11/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 44.66it/s, Loss=0.0702, Acc=97.83%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0702, Train Acc: 97.83%\n",
            "Val Loss: 0.0379, Val Acc: 98.74%\n",
            "Best Val Acc: 98.78% (Epoch 6)\n",
            "\n",
            "Epoch 12/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 44.99it/s, Loss=0.0672, Acc=97.95%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0672, Train Acc: 97.95%\n",
            "Val Loss: 0.0384, Val Acc: 98.66%\n",
            "Best Val Acc: 98.78% (Epoch 6)\n",
            "\n",
            "Epoch 13/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.32it/s, Loss=0.0602, Acc=98.18%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0602, Train Acc: 98.18%\n",
            "Val Loss: 0.0298, Val Acc: 98.89%\n",
            "Best Val Acc: 98.89% (Epoch 13)\n",
            "\n",
            "Epoch 14/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.84it/s, Loss=0.0529, Acc=98.44%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0529, Train Acc: 98.44%\n",
            "Val Loss: 0.0254, Val Acc: 99.14%\n",
            "Best Val Acc: 99.14% (Epoch 14)\n",
            "\n",
            "Epoch 15/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 44.81it/s, Loss=0.0451, Acc=98.62%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0451, Train Acc: 98.62%\n",
            "Val Loss: 0.0234, Val Acc: 99.20%\n",
            "Best Val Acc: 99.20% (Epoch 15)\n",
            "\n",
            "Epoch 16/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.54it/s, Loss=0.0398, Acc=98.75%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0398, Train Acc: 98.75%\n",
            "Val Loss: 0.0210, Val Acc: 99.30%\n",
            "Best Val Acc: 99.30% (Epoch 16)\n",
            "\n",
            "Epoch 17/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.88it/s, Loss=0.0330, Acc=99.06%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0330, Train Acc: 99.06%\n",
            "Val Loss: 0.0191, Val Acc: 99.33%\n",
            "Best Val Acc: 99.33% (Epoch 17)\n",
            "\n",
            "Epoch 18/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.72it/s, Loss=0.0295, Acc=99.14%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0295, Train Acc: 99.14%\n",
            "Val Loss: 0.0182, Val Acc: 99.33%\n",
            "Best Val Acc: 99.33% (Epoch 17)\n",
            "\n",
            "Epoch 19/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:19<00:00, 47.15it/s, Loss=0.0277, Acc=99.20%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0277, Train Acc: 99.20%\n",
            "Val Loss: 0.0182, Val Acc: 99.36%\n",
            "Best Val Acc: 99.36% (Epoch 19)\n",
            "\n",
            "========================================\n",
            "EXPERIMENT COMPLETED: Small_MNIST10\n",
            "========================================\n",
            "Best Validation Accuracy: 99.36%\n",
            "Target Achievement (99.4%): ✗\n",
            "Parameter Efficiency (<20k): ✓\n"
          ]
        }
      ],
      "source": [
        "exp_config = {\n",
        "      'model_class': Small_MNIST10,\n",
        "      'model_name': 'Small_MNIST10',\n",
        "      'epochs': 19,\n",
        "      'learning_rate': 0.001,\n",
        "      'scheduler_type': 'onecycle',\n",
        "      'use_augmentation': True,\n",
        "      'dropout_rate': 0.15\n",
        "  }\n",
        "\n",
        "wandb.init(project=\"cnn_mnist\", config=exp_config)\n",
        "cfg = wandb.config\n",
        "\n",
        "# ------------------------------\n",
        "# Data loaders (MNIST)\n",
        "# ------------------------------\n",
        "torch.manual_seed(42)\n",
        "\n",
        "create_and_run(exp_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60_AvBAKmqbp"
      },
      "source": [
        "Changed batch size to 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aInE-K2Dmo9q"
      },
      "outputs": [],
      "source": [
        "class Small_MNIST11(nn.Module):\n",
        "    \"\"\"\n",
        "    Small CNN Architecture v1\n",
        "    - Basic efficient design with BN and Dropout\n",
        "    - Uses Global Average Pooling\n",
        "    - Target: <20k parameters, >99.4% accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dropout_rate=0.1):\n",
        "        super(Small_MNIST11, self).__init__()\n",
        "\n",
        "        # Feature extraction layers\n",
        "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(8, 16, 1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "\n",
        "        # Pooling and regularization\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.dropout1 = nn.Dropout2d(dropout_rate)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(32, 64, 1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.dropout2 = nn.Dropout2d(dropout_rate * 1.5)\n",
        "\n",
        "        self.conv5_dw = nn.Conv2d(64, 64, 3, padding=1, groups=64, bias=False)\n",
        "        self.conv5_pw = nn.Conv2d(64, 64, 1, bias=False)\n",
        "        self.bn5 = nn.BatchNorm2d(64)\n",
        "        # Final classification layer\n",
        "        self.conv6 = nn.Conv2d(64, 10, 3, padding=1)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # Block 3 & Classification\n",
        "        x = self.conv5_dw(x)\n",
        "        x = self.conv5_pw(x)\n",
        "        x = F.relu(self.bn5(x))\n",
        "        x = self.conv6(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_VvStqzzm3Ps",
        "outputId": "54164e8f-3d96-4a19-e17f-d861aa63dbaa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>▁▄▄▆▆▇▇▇▇▇▇▇▇██████</td></tr><tr><td>test_loss</td><td>█▄▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_acc</td><td>▁▇▇▇▇██████████████</td></tr><tr><td>train/epoch_loss</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>99.36</td></tr><tr><td>test_loss</td><td>0.01815</td></tr><tr><td>train/epoch_acc</td><td>99.2</td></tr><tr><td>train/epoch_loss</td><td>0.02772</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">swift-firebrand-19</strong> at: <a href='https://wandb.ai/johnced/cnn_mnist/runs/2m30gpmr' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist/runs/2m30gpmr</a><br> View project at: <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250914_192054-2m30gpmr/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "creating run (0.0s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250914_193145-8b0gncmw</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/johnced/cnn_mnist/runs/8b0gncmw' target=\"_blank\">winter-mountain-20</a></strong> to <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/johnced/cnn_mnist/runs/8b0gncmw' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist/runs/8b0gncmw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Experimental Suite: MNIST_CNN_20250914_193147\n",
            "Target: 99.4% accuracy with <20k parameters in <20 epochs\n",
            "\n",
            "============================================================\n",
            "Running Experiment: Small_MNIST11\n",
            "============================================================\n",
            "Using device: cuda\n",
            "\n",
            "Model Requirements Check:\n",
            "  Total Parameters: 17,786\n",
            "  Under 20k params: ✓\n",
            "  Has Batch Normalization: ✓\n",
            "  Has Dropout: ✓\n",
            "  Has Global Average Pooling: ✓\n",
            "  Has Fully Connected Layer: ✗\n",
            "\n",
            "Starting Training for 19 epochs...\n",
            "\n",
            "Epoch 1/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 26.11it/s, Loss=1.3546, Acc=54.85%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.3546, Train Acc: 54.85%\n",
            "Val Loss: 0.3687, Val Acc: 92.05%\n",
            "Best Val Acc: 92.05% (Epoch 1)\n",
            "\n",
            "Epoch 2/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:16<00:00, 28.01it/s, Loss=0.2942, Acc=91.84%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2942, Train Acc: 91.84%\n",
            "Val Loss: 0.1329, Val Acc: 95.91%\n",
            "Best Val Acc: 95.91% (Epoch 2)\n",
            "\n",
            "Epoch 3/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 26.54it/s, Loss=0.1504, Acc=95.46%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1504, Train Acc: 95.46%\n",
            "Val Loss: 0.0762, Val Acc: 97.72%\n",
            "Best Val Acc: 97.72% (Epoch 3)\n",
            "\n",
            "Epoch 4/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 27.47it/s, Loss=0.1195, Acc=96.34%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1195, Train Acc: 96.34%\n",
            "Val Loss: 0.0746, Val Acc: 97.84%\n",
            "Best Val Acc: 97.84% (Epoch 4)\n",
            "\n",
            "Epoch 5/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 26.22it/s, Loss=0.1062, Acc=96.83%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1062, Train Acc: 96.83%\n",
            "Val Loss: 0.0546, Val Acc: 98.27%\n",
            "Best Val Acc: 98.27% (Epoch 5)\n",
            "\n",
            "Epoch 6/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:16<00:00, 27.79it/s, Loss=0.0914, Acc=97.13%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0914, Train Acc: 97.13%\n",
            "Val Loss: 0.0408, Val Acc: 98.65%\n",
            "Best Val Acc: 98.65% (Epoch 6)\n",
            "\n",
            "Epoch 7/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 26.34it/s, Loss=0.0752, Acc=97.76%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0752, Train Acc: 97.76%\n",
            "Val Loss: 0.0760, Val Acc: 97.56%\n",
            "Best Val Acc: 98.65% (Epoch 6)\n",
            "\n",
            "Epoch 8/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 27.33it/s, Loss=0.0756, Acc=97.68%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0756, Train Acc: 97.68%\n",
            "Val Loss: 0.0459, Val Acc: 98.53%\n",
            "Best Val Acc: 98.65% (Epoch 6)\n",
            "\n",
            "Epoch 9/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:18<00:00, 26.00it/s, Loss=0.0708, Acc=97.82%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0708, Train Acc: 97.82%\n",
            "Val Loss: 0.0378, Val Acc: 98.60%\n",
            "Best Val Acc: 98.65% (Epoch 6)\n",
            "\n",
            "Epoch 10/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:16<00:00, 27.87it/s, Loss=0.0632, Acc=98.07%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0632, Train Acc: 98.07%\n",
            "Val Loss: 0.0401, Val Acc: 98.76%\n",
            "Best Val Acc: 98.76% (Epoch 10)\n",
            "\n",
            "Epoch 11/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 26.65it/s, Loss=0.0602, Acc=98.15%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0602, Train Acc: 98.15%\n",
            "Val Loss: 0.0322, Val Acc: 99.04%\n",
            "Best Val Acc: 99.04% (Epoch 11)\n",
            "\n",
            "Epoch 12/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:16<00:00, 28.10it/s, Loss=0.0561, Acc=98.28%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0561, Train Acc: 98.28%\n",
            "Val Loss: 0.0246, Val Acc: 99.13%\n",
            "Best Val Acc: 99.13% (Epoch 12)\n",
            "\n",
            "Epoch 13/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:18<00:00, 24.92it/s, Loss=0.0501, Acc=98.45%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0501, Train Acc: 98.45%\n",
            "Val Loss: 0.0276, Val Acc: 99.16%\n",
            "Best Val Acc: 99.16% (Epoch 13)\n",
            "\n",
            "Epoch 14/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:16<00:00, 28.16it/s, Loss=0.0440, Acc=98.66%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0440, Train Acc: 98.66%\n",
            "Val Loss: 0.0242, Val Acc: 99.29%\n",
            "Best Val Acc: 99.29% (Epoch 14)\n",
            "\n",
            "Epoch 15/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 26.67it/s, Loss=0.0392, Acc=98.78%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0392, Train Acc: 98.78%\n",
            "Val Loss: 0.0202, Val Acc: 99.34%\n",
            "Best Val Acc: 99.34% (Epoch 15)\n",
            "\n",
            "Epoch 16/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:16<00:00, 28.02it/s, Loss=0.0337, Acc=98.98%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0337, Train Acc: 98.98%\n",
            "Val Loss: 0.0206, Val Acc: 99.33%\n",
            "Best Val Acc: 99.34% (Epoch 15)\n",
            "\n",
            "Epoch 17/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 27.28it/s, Loss=0.0309, Acc=99.09%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0309, Train Acc: 99.09%\n",
            "Val Loss: 0.0186, Val Acc: 99.40%\n",
            "Best Val Acc: 99.40% (Epoch 17)\n",
            "\n",
            "Epoch 18/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:16<00:00, 28.28it/s, Loss=0.0280, Acc=99.21%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0280, Train Acc: 99.21%\n",
            "Val Loss: 0.0176, Val Acc: 99.43%\n",
            "Best Val Acc: 99.43% (Epoch 18)\n",
            "\n",
            "Epoch 19/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:16<00:00, 27.93it/s, Loss=0.0259, Acc=99.25%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0259, Train Acc: 99.25%\n",
            "Val Loss: 0.0173, Val Acc: 99.51%\n",
            "Best Val Acc: 99.51% (Epoch 19)\n",
            "\n",
            "========================================\n",
            "EXPERIMENT COMPLETED: Small_MNIST11\n",
            "========================================\n",
            "Best Validation Accuracy: 99.51%\n",
            "Target Achievement (99.4%): ✓\n",
            "Parameter Efficiency (<20k): ✓\n"
          ]
        }
      ],
      "source": [
        "exp_config = {\n",
        "      'model_class': Small_MNIST11,\n",
        "      'model_name': 'Small_MNIST11',\n",
        "      'epochs': 19,\n",
        "      'learning_rate': 0.001,\n",
        "      'scheduler_type': 'onecycle',\n",
        "      'use_augmentation': True,\n",
        "      'dropout_rate': 0.15\n",
        "  }\n",
        "\n",
        "wandb.init(project=\"cnn_mnist\", config=exp_config)\n",
        "cfg = wandb.config\n",
        "\n",
        "# ------------------------------\n",
        "# Data loaders (MNIST)\n",
        "# ------------------------------\n",
        "torch.manual_seed(42)\n",
        "\n",
        "create_and_run(exp_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKtrhNUpnDpB"
      },
      "source": [
        "Changed architecture with groups with batch 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ml1TLpKmm7OG"
      },
      "outputs": [],
      "source": [
        "class Small_MNIST12(nn.Module):\n",
        "    \"\"\"\n",
        "    Small CNN Architecture v1\n",
        "    - Basic efficient design with BN and Dropout\n",
        "    - Uses Global Average Pooling\n",
        "    - Target: <20k parameters, >99.4% accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dropout_rate=0.1):\n",
        "        super(Small_MNIST12, self).__init__()\n",
        "\n",
        "        # Feature extraction layers\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, 1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # Pooling and regularization\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.dropout1 = nn.Dropout2d(dropout_rate)\n",
        "\n",
        "        #self.conv3 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        #self.bn3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv3_dw = nn.Conv2d(32, 32, 3, padding=1, groups=32, bias=False)\n",
        "        self.conv3_pw = nn.Conv2d(32, 32, 1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(32, 64, 1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.dropout2 = nn.Dropout2d(dropout_rate * 1.5)\n",
        "\n",
        "        self.conv5_dw = nn.Conv2d(64, 64, 3, padding=1, groups=64, bias=False)\n",
        "        self.conv5_pw = nn.Conv2d(64, 64, 1, bias=False)\n",
        "        self.bn5 = nn.BatchNorm2d(64)\n",
        "        # Final classification layer\n",
        "        self.conv6 = nn.Conv2d(64, 10, 3, padding=1)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # Block 2\n",
        "        #x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.conv3_dw(x)\n",
        "        x = self.conv3_pw(x)\n",
        "        x = F.relu(self.bn3(x))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # Block 3 & Classification\n",
        "        x = self.conv5_dw(x)\n",
        "        x = self.conv5_pw(x)\n",
        "        x = F.relu(self.bn5(x))\n",
        "        x = self.conv6(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKtQCX4xm7U2",
        "outputId": "9bb31f53-8e7b-4867-eb7d-a52295622803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 28, 28]             160\n",
            "       BatchNorm2d-2           [-1, 16, 28, 28]              32\n",
            "            Conv2d-3           [-1, 32, 30, 30]             544\n",
            "       BatchNorm2d-4           [-1, 32, 30, 30]              64\n",
            "         MaxPool2d-5           [-1, 32, 15, 15]               0\n",
            "         Dropout2d-6           [-1, 32, 15, 15]               0\n",
            "            Conv2d-7           [-1, 32, 15, 15]             288\n",
            "            Conv2d-8           [-1, 32, 15, 15]           1,024\n",
            "       BatchNorm2d-9           [-1, 32, 15, 15]              64\n",
            "           Conv2d-10           [-1, 64, 17, 17]           2,112\n",
            "      BatchNorm2d-11           [-1, 64, 17, 17]             128\n",
            "        MaxPool2d-12             [-1, 64, 8, 8]               0\n",
            "        Dropout2d-13             [-1, 64, 8, 8]               0\n",
            "           Conv2d-14             [-1, 64, 8, 8]             576\n",
            "           Conv2d-15             [-1, 64, 8, 8]           4,096\n",
            "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
            "           Conv2d-17             [-1, 10, 8, 8]           5,770\n",
            "AdaptiveAvgPool2d-18             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 14,986\n",
            "Trainable params: 14,986\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.35\n",
            "Params size (MB): 0.06\n",
            "Estimated Total Size (MB): 1.41\n",
            "----------------------------------------------------------------\n",
            "layer                          type   out_ch k         s         p         out(HxW)   RF(HxW)      jump     start       \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "conv1                          conv   16     3x3       1x1       1x1       28x28      3x3          1x1      0.50x0.50   \n",
            "conv2                          conv   32     1x1       1x1       1x1       30x30      3x3          1x1      -0.50x-0.50 \n",
            "pool1                          pool   -      2x2       2x2       0x0       15x15      4x4          2x2      0.00x0.00   \n",
            "conv3_dw                       conv   32     3x3       1x1       1x1       15x15      8x8          2x2      0.00x0.00   \n",
            "conv3_pw                       conv   32     1x1       1x1       0x0       15x15      8x8          2x2      0.00x0.00   \n",
            "conv4                          conv   64     1x1       1x1       1x1       17x17      8x8          2x2      -2.00x-2.00 \n",
            "pool2                          pool   -      2x2       2x2       0x0       8x8        10x10        4x4      -1.00x-1.00 \n",
            "conv5_dw                       conv   64     3x3       1x1       1x1       8x8        18x18        4x4      -1.00x-1.00 \n",
            "conv5_pw                       conv   64     1x1       1x1       0x0       8x8        18x18        4x4      -1.00x-1.00 \n",
            "conv6                          conv   10     3x3       1x1       1x1       8x8        26x26        4x4      -1.00x-1.00 \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Final output spatial size: 8 x 8\n",
            "Final receptive field: 26 x 26\n",
            "Final cumulative stride (jump): 4 x 4\n",
            "Center of top-left output unit relative to input pixel (0-index approx): -1.00 , -1.00\n"
          ]
        }
      ],
      "source": [
        "model_summary_and_rf(Small_MNIST12())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I8uigUR-mpEP",
        "outputId": "461bfe64-0846-4108-cd1c-c21f5740fa52"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>▁▅▆▆▇▇▆▇▇▇█████████</td></tr><tr><td>test_loss</td><td>█▃▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_acc</td><td>▁▇▇████████████████</td></tr><tr><td>train/epoch_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>99.51</td></tr><tr><td>test_loss</td><td>0.01731</td></tr><tr><td>train/epoch_acc</td><td>99.24667</td></tr><tr><td>train/epoch_loss</td><td>0.02589</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">winter-mountain-20</strong> at: <a href='https://wandb.ai/johnced/cnn_mnist/runs/8b0gncmw' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist/runs/8b0gncmw</a><br> View project at: <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250914_193145-8b0gncmw/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "creating run (0.0s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250914_194003-6waj8pcp</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/johnced/cnn_mnist/runs/6waj8pcp' target=\"_blank\">lucky-silence-21</a></strong> to <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/johnced/cnn_mnist/runs/6waj8pcp' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist/runs/6waj8pcp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Experimental Suite: MNIST_CNN_20250914_194004\n",
            "Target: 99.4% accuracy with <20k parameters in <20 epochs\n",
            "\n",
            "============================================================\n",
            "Running Experiment: Small_MNIST12\n",
            "============================================================\n",
            "Using device: cuda\n",
            "\n",
            "Model Requirements Check:\n",
            "  Total Parameters: 14,986\n",
            "  Under 20k params: ✓\n",
            "  Has Batch Normalization: ✓\n",
            "  Has Dropout: ✓\n",
            "  Has Global Average Pooling: ✓\n",
            "  Has Fully Connected Layer: ✗\n",
            "\n",
            "Starting Training for 19 epochs...\n",
            "\n",
            "Epoch 1/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:18<00:00, 25.84it/s, Loss=1.4606, Acc=50.13%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.4606, Train Acc: 50.13%\n",
            "Val Loss: 0.4591, Val Acc: 88.67%\n",
            "Best Val Acc: 88.67% (Epoch 1)\n",
            "\n",
            "Epoch 2/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 27.21it/s, Loss=0.3551, Acc=90.12%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3551, Train Acc: 90.12%\n",
            "Val Loss: 0.1269, Val Acc: 96.54%\n",
            "Best Val Acc: 96.54% (Epoch 2)\n",
            "\n",
            "Epoch 3/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 26.45it/s, Loss=0.1694, Acc=95.01%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1694, Train Acc: 95.01%\n",
            "Val Loss: 0.0793, Val Acc: 97.45%\n",
            "Best Val Acc: 97.45% (Epoch 3)\n",
            "\n",
            "Epoch 4/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:16<00:00, 27.69it/s, Loss=0.1308, Acc=96.11%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1308, Train Acc: 96.11%\n",
            "Val Loss: 0.0665, Val Acc: 98.05%\n",
            "Best Val Acc: 98.05% (Epoch 4)\n",
            "\n",
            "Epoch 5/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:19<00:00, 24.57it/s, Loss=0.1182, Acc=96.33%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1182, Train Acc: 96.33%\n",
            "Val Loss: 0.0813, Val Acc: 97.49%\n",
            "Best Val Acc: 98.05% (Epoch 4)\n",
            "\n",
            "Epoch 6/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 27.21it/s, Loss=0.1005, Acc=96.92%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1005, Train Acc: 96.92%\n",
            "Val Loss: 0.0440, Val Acc: 98.49%\n",
            "Best Val Acc: 98.49% (Epoch 6)\n",
            "\n",
            "Epoch 7/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 26.16it/s, Loss=0.0885, Acc=97.28%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0885, Train Acc: 97.28%\n",
            "Val Loss: 0.0906, Val Acc: 97.07%\n",
            "Best Val Acc: 98.49% (Epoch 6)\n",
            "\n",
            "Epoch 8/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 27.21it/s, Loss=0.0839, Acc=97.45%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0839, Train Acc: 97.45%\n",
            "Val Loss: 0.0420, Val Acc: 98.61%\n",
            "Best Val Acc: 98.61% (Epoch 8)\n",
            "\n",
            "Epoch 9/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 27.07it/s, Loss=0.0779, Acc=97.60%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0779, Train Acc: 97.60%\n",
            "Val Loss: 0.0342, Val Acc: 98.85%\n",
            "Best Val Acc: 98.85% (Epoch 9)\n",
            "\n",
            "Epoch 10/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 27.44it/s, Loss=0.0717, Acc=97.75%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0717, Train Acc: 97.75%\n",
            "Val Loss: 0.0338, Val Acc: 98.84%\n",
            "Best Val Acc: 98.85% (Epoch 9)\n",
            "\n",
            "Epoch 11/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 27.45it/s, Loss=0.0663, Acc=97.91%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0663, Train Acc: 97.91%\n",
            "Val Loss: 0.0318, Val Acc: 98.98%\n",
            "Best Val Acc: 98.98% (Epoch 11)\n",
            "\n",
            "Epoch 12/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:16<00:00, 27.72it/s, Loss=0.0626, Acc=98.07%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0626, Train Acc: 98.07%\n",
            "Val Loss: 0.0317, Val Acc: 98.93%\n",
            "Best Val Acc: 98.98% (Epoch 11)\n",
            "\n",
            "Epoch 13/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:18<00:00, 26.03it/s, Loss=0.0549, Acc=98.35%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0549, Train Acc: 98.35%\n",
            "Val Loss: 0.0266, Val Acc: 99.12%\n",
            "Best Val Acc: 99.12% (Epoch 13)\n",
            "\n",
            "Epoch 14/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 27.12it/s, Loss=0.0481, Acc=98.58%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0481, Train Acc: 98.58%\n",
            "Val Loss: 0.0236, Val Acc: 99.21%\n",
            "Best Val Acc: 99.21% (Epoch 14)\n",
            "\n",
            "Epoch 15/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 27.38it/s, Loss=0.0453, Acc=98.62%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0453, Train Acc: 98.62%\n",
            "Val Loss: 0.0215, Val Acc: 99.23%\n",
            "Best Val Acc: 99.23% (Epoch 15)\n",
            "\n",
            "Epoch 16/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 26.59it/s, Loss=0.0389, Acc=98.83%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0389, Train Acc: 98.83%\n",
            "Val Loss: 0.0213, Val Acc: 99.29%\n",
            "Best Val Acc: 99.29% (Epoch 16)\n",
            "\n",
            "Epoch 17/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 27.58it/s, Loss=0.0348, Acc=99.01%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0348, Train Acc: 99.01%\n",
            "Val Loss: 0.0189, Val Acc: 99.40%\n",
            "Best Val Acc: 99.40% (Epoch 17)\n",
            "\n",
            "Epoch 18/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:17<00:00, 26.61it/s, Loss=0.0318, Acc=99.08%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0318, Train Acc: 99.08%\n",
            "Val Loss: 0.0182, Val Acc: 99.42%\n",
            "Best Val Acc: 99.42% (Epoch 18)\n",
            "\n",
            "Epoch 19/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 469/469 [00:16<00:00, 27.72it/s, Loss=0.0306, Acc=99.10%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0306, Train Acc: 99.10%\n",
            "Val Loss: 0.0185, Val Acc: 99.46%\n",
            "Best Val Acc: 99.46% (Epoch 19)\n",
            "\n",
            "========================================\n",
            "EXPERIMENT COMPLETED: Small_MNIST12\n",
            "========================================\n",
            "Best Validation Accuracy: 99.46%\n",
            "Target Achievement (99.4%): ✓\n",
            "Parameter Efficiency (<20k): ✓\n"
          ]
        }
      ],
      "source": [
        "exp_config = {\n",
        "      'model_class': Small_MNIST12,\n",
        "      'model_name': 'Small_MNIST12',\n",
        "      'epochs': 19,\n",
        "      'learning_rate': 1e-3,\n",
        "      'scheduler_type': 'onecycle',\n",
        "      'use_augmentation': True,\n",
        "      'dropout_rate': 0.15\n",
        "  }\n",
        "\n",
        "wandb.init(project=\"cnn_mnist\", config=exp_config)\n",
        "cfg = wandb.config\n",
        "\n",
        "# ------------------------------\n",
        "# Data loaders (MNIST)\n",
        "# ------------------------------\n",
        "torch.manual_seed(42)\n",
        "\n",
        "create_and_run(exp_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVYuGDiBnslk"
      },
      "source": [
        "Made corrections to padding and bias, batch size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UZTE5xNnWPo"
      },
      "outputs": [],
      "source": [
        "class Small_MNIST13(nn.Module):\n",
        "    \"\"\"\n",
        "    Small CNN Architecture v1\n",
        "    - Basic efficient design with BN and Dropout\n",
        "    - Uses Global Average Pooling\n",
        "    - Target: <20k parameters, >99.4% accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dropout_rate=0.1):\n",
        "        super(Small_MNIST13, self).__init__()\n",
        "\n",
        "        # Feature extraction layers\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, 1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # Pooling and regularization\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.dropout1 = nn.Dropout2d(dropout_rate)\n",
        "\n",
        "        #self.conv3 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        #self.bn3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv3_dw = nn.Conv2d(32, 32, 3, padding=1, groups=32, bias=False)\n",
        "        self.conv3_pw = nn.Conv2d(32, 32, 1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(32, 64, 1, padding=1, bias=False)\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.dropout2 = nn.Dropout2d(dropout_rate * 1.5)\n",
        "\n",
        "        self.conv5_dw = nn.Conv2d(64, 64, 3, padding=1, groups=64, bias=False)\n",
        "        self.conv5_pw = nn.Conv2d(64, 64, 1, bias=False)\n",
        "        self.bn5 = nn.BatchNorm2d(64)\n",
        "        # Final classification layer\n",
        "        self.conv6 = nn.Conv2d(64, 10, 3, padding=1, bias=True)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # Block 2\n",
        "        #x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.conv3_dw(x)\n",
        "        x = self.conv3_pw(x)\n",
        "        x = F.relu(self.bn3(x))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # Block 3 & Classification\n",
        "        x = self.conv5_dw(x)\n",
        "        x = self.conv5_pw(x)\n",
        "        x = F.relu(self.bn5(x))\n",
        "        x = self.conv6(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOgXgh0cmpfN",
        "outputId": "5da48fa0-8e1c-4225-831d-3232596f471a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 28, 28]             144\n",
            "       BatchNorm2d-2           [-1, 16, 28, 28]              32\n",
            "            Conv2d-3           [-1, 32, 28, 28]             512\n",
            "       BatchNorm2d-4           [-1, 32, 28, 28]              64\n",
            "         MaxPool2d-5           [-1, 32, 14, 14]               0\n",
            "         Dropout2d-6           [-1, 32, 14, 14]               0\n",
            "            Conv2d-7           [-1, 32, 14, 14]             288\n",
            "            Conv2d-8           [-1, 32, 14, 14]           1,024\n",
            "       BatchNorm2d-9           [-1, 32, 14, 14]              64\n",
            "           Conv2d-10           [-1, 64, 16, 16]           2,048\n",
            "      BatchNorm2d-11           [-1, 64, 16, 16]             128\n",
            "        MaxPool2d-12             [-1, 64, 8, 8]               0\n",
            "        Dropout2d-13             [-1, 64, 8, 8]               0\n",
            "           Conv2d-14             [-1, 64, 8, 8]             576\n",
            "           Conv2d-15             [-1, 64, 8, 8]           4,096\n",
            "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
            "           Conv2d-17             [-1, 10, 8, 8]           5,770\n",
            "AdaptiveAvgPool2d-18             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 14,874\n",
            "Trainable params: 14,874\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.22\n",
            "Params size (MB): 0.06\n",
            "Estimated Total Size (MB): 1.28\n",
            "----------------------------------------------------------------\n",
            "layer                          type   out_ch k         s         p         out(HxW)   RF(HxW)      jump     start       \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "conv1                          conv   16     3x3       1x1       1x1       28x28      3x3          1x1      0.50x0.50   \n",
            "conv2                          conv   32     1x1       1x1       0x0       28x28      3x3          1x1      0.50x0.50   \n",
            "pool1                          pool   -      2x2       2x2       0x0       14x14      4x4          2x2      1.00x1.00   \n",
            "conv3_dw                       conv   32     3x3       1x1       1x1       14x14      8x8          2x2      1.00x1.00   \n",
            "conv3_pw                       conv   32     1x1       1x1       0x0       14x14      8x8          2x2      1.00x1.00   \n",
            "conv4                          conv   64     1x1       1x1       1x1       16x16      8x8          2x2      -1.00x-1.00 \n",
            "pool2                          pool   -      2x2       2x2       0x0       8x8        10x10        4x4      0.00x0.00   \n",
            "conv5_dw                       conv   64     3x3       1x1       1x1       8x8        18x18        4x4      0.00x0.00   \n",
            "conv5_pw                       conv   64     1x1       1x1       0x0       8x8        18x18        4x4      0.00x0.00   \n",
            "conv6                          conv   10     3x3       1x1       1x1       8x8        26x26        4x4      0.00x0.00   \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Final output spatial size: 8 x 8\n",
            "Final receptive field: 26 x 26\n",
            "Final cumulative stride (jump): 4 x 4\n",
            "Center of top-left output unit relative to input pixel (0-index approx): 0.00 , 0.00\n"
          ]
        }
      ],
      "source": [
        "model_summary_and_rf(Small_MNIST13())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rxqYNQflnbKG",
        "outputId": "2b6760f5-98db-4d5a-afe8-375b974eac91"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>▁▆▇▇▇▇▆▇███████████</td></tr><tr><td>test_loss</td><td>█▃▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_acc</td><td>▁▇▇████████████████</td></tr><tr><td>train/epoch_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>99.46</td></tr><tr><td>test_loss</td><td>0.01851</td></tr><tr><td>train/epoch_acc</td><td>99.1</td></tr><tr><td>train/epoch_loss</td><td>0.03062</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lucky-silence-21</strong> at: <a href='https://wandb.ai/johnced/cnn_mnist/runs/6waj8pcp' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist/runs/6waj8pcp</a><br> View project at: <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250914_194003-6waj8pcp/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "creating run (0.0s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250914_194952-ievq5e8q</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/johnced/cnn_mnist/runs/ievq5e8q' target=\"_blank\">whole-brook-22</a></strong> to <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/johnced/cnn_mnist' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/johnced/cnn_mnist/runs/ievq5e8q' target=\"_blank\">https://wandb.ai/johnced/cnn_mnist/runs/ievq5e8q</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Experimental Suite: MNIST_CNN_20250914_194954\n",
            "Target: 99.4% accuracy with <20k parameters in <20 epochs\n",
            "\n",
            "============================================================\n",
            "Running Experiment: Small_MNIST13\n",
            "============================================================\n",
            "Using device: cuda\n",
            "\n",
            "Model Requirements Check:\n",
            "  Total Parameters: 14,874\n",
            "  Under 20k params: ✓\n",
            "  Has Batch Normalization: ✓\n",
            "  Has Dropout: ✓\n",
            "  Has Global Average Pooling: ✓\n",
            "  Has Fully Connected Layer: ✗\n",
            "\n",
            "Starting Training for 19 epochs...\n",
            "\n",
            "Epoch 1/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 42.85it/s, Loss=1.2534, Acc=57.53%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2534, Train Acc: 57.53%\n",
            "Val Loss: 0.3353, Val Acc: 92.53%\n",
            "Best Val Acc: 92.53% (Epoch 1)\n",
            "\n",
            "Epoch 2/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 43.01it/s, Loss=0.2749, Acc=92.27%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2749, Train Acc: 92.27%\n",
            "Val Loss: 0.0893, Val Acc: 97.33%\n",
            "Best Val Acc: 97.33% (Epoch 2)\n",
            "\n",
            "Epoch 3/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 43.69it/s, Loss=0.1653, Acc=94.97%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1653, Train Acc: 94.97%\n",
            "Val Loss: 0.0805, Val Acc: 97.36%\n",
            "Best Val Acc: 97.36% (Epoch 3)\n",
            "\n",
            "Epoch 4/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 44.53it/s, Loss=0.1378, Acc=95.67%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1378, Train Acc: 95.67%\n",
            "Val Loss: 0.0463, Val Acc: 98.51%\n",
            "Best Val Acc: 98.51% (Epoch 4)\n",
            "\n",
            "Epoch 5/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 44.98it/s, Loss=0.1207, Acc=96.30%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1207, Train Acc: 96.30%\n",
            "Val Loss: 0.0489, Val Acc: 98.41%\n",
            "Best Val Acc: 98.51% (Epoch 4)\n",
            "\n",
            "Epoch 6/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:22<00:00, 41.91it/s, Loss=0.1074, Acc=96.70%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1074, Train Acc: 96.70%\n",
            "Val Loss: 0.0509, Val Acc: 98.30%\n",
            "Best Val Acc: 98.51% (Epoch 4)\n",
            "\n",
            "Epoch 7/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 44.46it/s, Loss=0.0973, Acc=97.08%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0973, Train Acc: 97.08%\n",
            "Val Loss: 0.0532, Val Acc: 98.34%\n",
            "Best Val Acc: 98.51% (Epoch 4)\n",
            "\n",
            "Epoch 8/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 44.34it/s, Loss=0.0917, Acc=97.18%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0917, Train Acc: 97.18%\n",
            "Val Loss: 0.0596, Val Acc: 98.09%\n",
            "Best Val Acc: 98.51% (Epoch 4)\n",
            "\n",
            "Epoch 9/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 44.27it/s, Loss=0.0873, Acc=97.34%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0873, Train Acc: 97.34%\n",
            "Val Loss: 0.0397, Val Acc: 98.79%\n",
            "Best Val Acc: 98.79% (Epoch 9)\n",
            "\n",
            "Epoch 10/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 46.16it/s, Loss=0.0805, Acc=97.55%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0805, Train Acc: 97.55%\n",
            "Val Loss: 0.0442, Val Acc: 98.51%\n",
            "Best Val Acc: 98.79% (Epoch 9)\n",
            "\n",
            "Epoch 11/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.10it/s, Loss=0.0788, Acc=97.59%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0788, Train Acc: 97.59%\n",
            "Val Loss: 0.0385, Val Acc: 98.83%\n",
            "Best Val Acc: 98.83% (Epoch 11)\n",
            "\n",
            "Epoch 12/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 43.90it/s, Loss=0.0682, Acc=97.91%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0682, Train Acc: 97.91%\n",
            "Val Loss: 0.0383, Val Acc: 98.86%\n",
            "Best Val Acc: 98.86% (Epoch 12)\n",
            "\n",
            "Epoch 13/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:22<00:00, 41.91it/s, Loss=0.0621, Acc=98.13%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0621, Train Acc: 98.13%\n",
            "Val Loss: 0.0270, Val Acc: 99.18%\n",
            "Best Val Acc: 99.18% (Epoch 13)\n",
            "\n",
            "Epoch 14/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 43.16it/s, Loss=0.0550, Acc=98.36%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0550, Train Acc: 98.36%\n",
            "Val Loss: 0.0300, Val Acc: 99.02%\n",
            "Best Val Acc: 99.18% (Epoch 13)\n",
            "\n",
            "Epoch 15/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 44.85it/s, Loss=0.0491, Acc=98.53%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0491, Train Acc: 98.53%\n",
            "Val Loss: 0.0278, Val Acc: 99.15%\n",
            "Best Val Acc: 99.18% (Epoch 13)\n",
            "\n",
            "Epoch 16/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 45.37it/s, Loss=0.0428, Acc=98.74%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0428, Train Acc: 98.74%\n",
            "Val Loss: 0.0205, Val Acc: 99.38%\n",
            "Best Val Acc: 99.38% (Epoch 16)\n",
            "\n",
            "Epoch 17/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:20<00:00, 44.68it/s, Loss=0.0373, Acc=98.95%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0373, Train Acc: 98.95%\n",
            "Val Loss: 0.0184, Val Acc: 99.48%\n",
            "Best Val Acc: 99.48% (Epoch 17)\n",
            "\n",
            "Epoch 18/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 44.54it/s, Loss=0.0343, Acc=98.96%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0343, Train Acc: 98.96%\n",
            "Val Loss: 0.0184, Val Acc: 99.48%\n",
            "Best Val Acc: 99.48% (Epoch 17)\n",
            "\n",
            "Epoch 19/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:21<00:00, 44.32it/s, Loss=0.0323, Acc=99.03%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0323, Train Acc: 99.03%\n",
            "Val Loss: 0.0176, Val Acc: 99.49%\n",
            "Best Val Acc: 99.49% (Epoch 19)\n",
            "\n",
            "========================================\n",
            "EXPERIMENT COMPLETED: Small_MNIST13\n",
            "========================================\n",
            "Best Validation Accuracy: 99.49%\n",
            "Target Achievement (99.4%): ✓\n",
            "Parameter Efficiency (<20k): ✓\n"
          ]
        }
      ],
      "source": [
        "exp_config = {\n",
        "      'model_class': Small_MNIST13,\n",
        "      'model_name': 'Small_MNIST13',\n",
        "      'epochs': 19,\n",
        "      'learning_rate': 1e-3,\n",
        "      'scheduler_type': 'onecycle',\n",
        "      'use_augmentation': True,\n",
        "      'dropout_rate': 0.15\n",
        "  }\n",
        "\n",
        "wandb.init(project=\"cnn_mnist\", config=exp_config)\n",
        "cfg = wandb.config\n",
        "\n",
        "# ------------------------------\n",
        "# Data loaders (MNIST)\n",
        "# ------------------------------\n",
        "torch.manual_seed(42)\n",
        "\n",
        "create_and_run(exp_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the metrics"
      ],
      "metadata": {
        "id": "wbfuKG8aXZsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('training_log_metrics.csv')\n",
        "\n",
        "# Extract the metrics\n",
        "train_loss = df['train_loss']\n",
        "train_acc = df['train_acc']\n",
        "val_loss = df['val_loss']\n",
        "val_acc = df['val_acc']\n",
        "\n",
        "# Plot the metrics\n",
        "fig, axs = plt.subplots(2,2,figsize=(15,10))\n",
        "axs[0, 0].plot(train_loss)\n",
        "axs[0, 0].set_title(\"Training Loss\")\n",
        "axs[1, 0].plot(train_acc)\n",
        "axs[1, 0].set_title(\"Training Accuracy\")\n",
        "axs[0, 1].plot(val_loss)\n",
        "axs[0, 1].set_title(\"Validation Loss\")\n",
        "axs[1, 1].plot(val_acc)\n",
        "axs[1, 1].set_title(\"Validation Accuracy\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "0gqFDj63XYPl",
        "outputId": "e473e916-d18b-4210-ee0d-a9ffd0b4e6a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZtjzgmcHXdKR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}